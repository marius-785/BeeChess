{
  "best_global_step": 3711,
  "best_metric": 2.5913708209991455,
  "best_model_checkpoint": "./VanillaTrain/checkpoint-3711",
  "epoch": 1.0,
  "eval_steps": 500,
  "global_step": 3711,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.026946914578280787,
      "grad_norm": 2.5578861236572266,
      "learning_rate": 0.00013306451612903227,
      "loss": 6.6223,
      "step": 100
    },
    {
      "epoch": 0.05389382915656157,
      "grad_norm": 0.8265847563743591,
      "learning_rate": 0.0002674731182795699,
      "loss": 5.3558,
      "step": 200
    },
    {
      "epoch": 0.08084074373484236,
      "grad_norm": 0.7170027494430542,
      "learning_rate": 0.00040188172043010753,
      "loss": 4.478,
      "step": 300
    },
    {
      "epoch": 0.10778765831312315,
      "grad_norm": 0.8607144951820374,
      "learning_rate": 0.0004959568733153639,
      "loss": 4.1105,
      "step": 400
    },
    {
      "epoch": 0.13473457289140395,
      "grad_norm": 0.8451253771781921,
      "learning_rate": 0.0004809823300389338,
      "loss": 3.8074,
      "step": 500
    },
    {
      "epoch": 0.16168148746968472,
      "grad_norm": 0.8403322696685791,
      "learning_rate": 0.0004660077867625038,
      "loss": 3.5999,
      "step": 600
    },
    {
      "epoch": 0.18862840204796552,
      "grad_norm": 0.8579773902893066,
      "learning_rate": 0.0004510332434860737,
      "loss": 3.4474,
      "step": 700
    },
    {
      "epoch": 0.2155753166262463,
      "grad_norm": 0.8937296867370605,
      "learning_rate": 0.0004360587002096436,
      "loss": 3.3389,
      "step": 800
    },
    {
      "epoch": 0.2425222312045271,
      "grad_norm": 0.8800008296966553,
      "learning_rate": 0.00042108415693321356,
      "loss": 3.2383,
      "step": 900
    },
    {
      "epoch": 0.2694691457828079,
      "grad_norm": 0.8772998452186584,
      "learning_rate": 0.00040610961365678347,
      "loss": 3.1741,
      "step": 1000
    },
    {
      "epoch": 0.29641606036108864,
      "grad_norm": 0.9222900867462158,
      "learning_rate": 0.0003911350703803534,
      "loss": 3.1143,
      "step": 1100
    },
    {
      "epoch": 0.32336297493936944,
      "grad_norm": 1.009170651435852,
      "learning_rate": 0.00037616052710392334,
      "loss": 3.071,
      "step": 1200
    },
    {
      "epoch": 0.35030988951765024,
      "grad_norm": 0.7703465819358826,
      "learning_rate": 0.0003611859838274933,
      "loss": 3.0261,
      "step": 1300
    },
    {
      "epoch": 0.37725680409593104,
      "grad_norm": 0.798287034034729,
      "learning_rate": 0.0003462114405510632,
      "loss": 2.9926,
      "step": 1400
    },
    {
      "epoch": 0.4042037186742118,
      "grad_norm": 0.824016809463501,
      "learning_rate": 0.0003312368972746331,
      "loss": 2.9571,
      "step": 1500
    },
    {
      "epoch": 0.4311506332524926,
      "grad_norm": 0.839212954044342,
      "learning_rate": 0.0003162623539982031,
      "loss": 2.9313,
      "step": 1600
    },
    {
      "epoch": 0.4580975478307734,
      "grad_norm": 0.8447386622428894,
      "learning_rate": 0.000301287810721773,
      "loss": 2.9093,
      "step": 1700
    },
    {
      "epoch": 0.4850444624090542,
      "grad_norm": 0.9280627369880676,
      "learning_rate": 0.0002863132674453429,
      "loss": 2.8912,
      "step": 1800
    },
    {
      "epoch": 0.511991376987335,
      "grad_norm": 0.7968567609786987,
      "learning_rate": 0.00027133872416891286,
      "loss": 2.8712,
      "step": 1900
    },
    {
      "epoch": 0.5389382915656158,
      "grad_norm": 0.8561905026435852,
      "learning_rate": 0.0002563641808924828,
      "loss": 2.8517,
      "step": 2000
    },
    {
      "epoch": 0.5658852061438965,
      "grad_norm": 0.8490586876869202,
      "learning_rate": 0.0002413896376160527,
      "loss": 2.841,
      "step": 2100
    },
    {
      "epoch": 0.5928321207221773,
      "grad_norm": 0.7765213847160339,
      "learning_rate": 0.00022641509433962264,
      "loss": 2.8209,
      "step": 2200
    },
    {
      "epoch": 0.6197790353004581,
      "grad_norm": 0.8016490936279297,
      "learning_rate": 0.00021144055106319258,
      "loss": 2.81,
      "step": 2300
    },
    {
      "epoch": 0.6467259498787389,
      "grad_norm": 0.8403600454330444,
      "learning_rate": 0.0001964660077867625,
      "loss": 2.797,
      "step": 2400
    },
    {
      "epoch": 0.6736728644570197,
      "grad_norm": 0.8358396887779236,
      "learning_rate": 0.00018149146451033245,
      "loss": 2.7869,
      "step": 2500
    },
    {
      "epoch": 0.7006197790353005,
      "grad_norm": 0.7896731495857239,
      "learning_rate": 0.00016651692123390236,
      "loss": 2.7753,
      "step": 2600
    },
    {
      "epoch": 0.7275666936135813,
      "grad_norm": 0.7875754237174988,
      "learning_rate": 0.0001515423779574723,
      "loss": 2.7694,
      "step": 2700
    },
    {
      "epoch": 0.7545136081918621,
      "grad_norm": 0.7937830090522766,
      "learning_rate": 0.00013656783468104223,
      "loss": 2.7632,
      "step": 2800
    },
    {
      "epoch": 0.7814605227701428,
      "grad_norm": 0.7947142720222473,
      "learning_rate": 0.00012159329140461216,
      "loss": 2.7538,
      "step": 2900
    },
    {
      "epoch": 0.8084074373484236,
      "grad_norm": 0.8103567361831665,
      "learning_rate": 0.00010661874812818209,
      "loss": 2.7509,
      "step": 3000
    },
    {
      "epoch": 0.8353543519267044,
      "grad_norm": 0.7248526811599731,
      "learning_rate": 9.164420485175202e-05,
      "loss": 2.7391,
      "step": 3100
    },
    {
      "epoch": 0.8623012665049852,
      "grad_norm": 0.7195338010787964,
      "learning_rate": 7.666966157532196e-05,
      "loss": 2.7356,
      "step": 3200
    },
    {
      "epoch": 0.889248181083266,
      "grad_norm": 0.725389838218689,
      "learning_rate": 6.169511829889188e-05,
      "loss": 2.732,
      "step": 3300
    },
    {
      "epoch": 0.9161950956615468,
      "grad_norm": 0.7693021893501282,
      "learning_rate": 4.6720575022461816e-05,
      "loss": 2.7284,
      "step": 3400
    },
    {
      "epoch": 0.9431420102398276,
      "grad_norm": 0.721655011177063,
      "learning_rate": 3.1746031746031745e-05,
      "loss": 2.7207,
      "step": 3500
    },
    {
      "epoch": 0.9700889248181084,
      "grad_norm": 0.6983921527862549,
      "learning_rate": 1.6771488469601677e-05,
      "loss": 2.7217,
      "step": 3600
    },
    {
      "epoch": 0.9970358393963891,
      "grad_norm": 0.6753278374671936,
      "learning_rate": 1.7969451931716085e-06,
      "loss": 2.7203,
      "step": 3700
    },
    {
      "epoch": 1.0,
      "eval_loss": 2.5913708209991455,
      "eval_runtime": 2.8852,
      "eval_samples_per_second": 1732.984,
      "eval_steps_per_second": 27.381,
      "step": 3711
    }
  ],
  "logging_steps": 100,
  "max_steps": 3711,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 965640192000000.0,
  "train_batch_size": 256,
  "trial_name": null,
  "trial_params": null
}
