{
  "best_global_step": 3711,
  "best_metric": 0.5769700407981873,
  "best_model_checkpoint": "./O15/checkpoint-3711",
  "epoch": 1.0,
  "eval_steps": 500,
  "global_step": 3711,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.026946914578280787,
      "grad_norm": 2.1218228340148926,
      "learning_rate": 0.00013306451612903227,
      "loss": 3.9118,
      "step": 100
    },
    {
      "epoch": 0.05389382915656157,
      "grad_norm": 1.6679675579071045,
      "learning_rate": 0.0002674731182795699,
      "loss": 2.9208,
      "step": 200
    },
    {
      "epoch": 0.08084074373484236,
      "grad_norm": 0.7084655165672302,
      "learning_rate": 0.00040188172043010753,
      "loss": 2.1982,
      "step": 300
    },
    {
      "epoch": 0.10778765831312315,
      "grad_norm": 1.7567170858383179,
      "learning_rate": 0.0004959568733153639,
      "loss": 1.8808,
      "step": 400
    },
    {
      "epoch": 0.13473457289140395,
      "grad_norm": 1.9408259391784668,
      "learning_rate": 0.0004809823300389338,
      "loss": 1.7003,
      "step": 500
    },
    {
      "epoch": 0.16168148746968472,
      "grad_norm": 0.7673019170761108,
      "learning_rate": 0.0004660077867625038,
      "loss": 1.5266,
      "step": 600
    },
    {
      "epoch": 0.18862840204796552,
      "grad_norm": 0.9964791536331177,
      "learning_rate": 0.0004510332434860737,
      "loss": 1.3511,
      "step": 700
    },
    {
      "epoch": 0.2155753166262463,
      "grad_norm": 0.9371532797813416,
      "learning_rate": 0.0004360587002096436,
      "loss": 1.2196,
      "step": 800
    },
    {
      "epoch": 0.2425222312045271,
      "grad_norm": 0.913445234298706,
      "learning_rate": 0.00042108415693321356,
      "loss": 1.0795,
      "step": 900
    },
    {
      "epoch": 0.2694691457828079,
      "grad_norm": 0.8220518827438354,
      "learning_rate": 0.00040610961365678347,
      "loss": 0.9594,
      "step": 1000
    },
    {
      "epoch": 0.29641606036108864,
      "grad_norm": 0.631252110004425,
      "learning_rate": 0.0003911350703803534,
      "loss": 0.8905,
      "step": 1100
    },
    {
      "epoch": 0.32336297493936944,
      "grad_norm": 0.7427226305007935,
      "learning_rate": 0.00037616052710392334,
      "loss": 0.8405,
      "step": 1200
    },
    {
      "epoch": 0.35030988951765024,
      "grad_norm": 0.6764428019523621,
      "learning_rate": 0.0003611859838274933,
      "loss": 0.8022,
      "step": 1300
    },
    {
      "epoch": 0.37725680409593104,
      "grad_norm": 0.7032347917556763,
      "learning_rate": 0.0003462114405510632,
      "loss": 0.7704,
      "step": 1400
    },
    {
      "epoch": 0.4042037186742118,
      "grad_norm": 0.5971457362174988,
      "learning_rate": 0.0003312368972746331,
      "loss": 0.7494,
      "step": 1500
    },
    {
      "epoch": 0.4311506332524926,
      "grad_norm": 0.5626103281974792,
      "learning_rate": 0.0003162623539982031,
      "loss": 0.7308,
      "step": 1600
    },
    {
      "epoch": 0.4580975478307734,
      "grad_norm": 0.5418901443481445,
      "learning_rate": 0.000301287810721773,
      "loss": 0.7164,
      "step": 1700
    },
    {
      "epoch": 0.4850444624090542,
      "grad_norm": 0.5517247319221497,
      "learning_rate": 0.0002863132674453429,
      "loss": 0.7048,
      "step": 1800
    },
    {
      "epoch": 0.511991376987335,
      "grad_norm": 0.5902808904647827,
      "learning_rate": 0.00027133872416891286,
      "loss": 0.6952,
      "step": 1900
    },
    {
      "epoch": 0.5389382915656158,
      "grad_norm": 0.590650737285614,
      "learning_rate": 0.0002563641808924828,
      "loss": 0.6853,
      "step": 2000
    },
    {
      "epoch": 0.5658852061438965,
      "grad_norm": 0.5129228830337524,
      "learning_rate": 0.0002413896376160527,
      "loss": 0.6789,
      "step": 2100
    },
    {
      "epoch": 0.5928321207221773,
      "grad_norm": 0.6060047149658203,
      "learning_rate": 0.00022641509433962264,
      "loss": 0.6721,
      "step": 2200
    },
    {
      "epoch": 0.6197790353004581,
      "grad_norm": 0.5459957122802734,
      "learning_rate": 0.00021144055106319258,
      "loss": 0.6661,
      "step": 2300
    },
    {
      "epoch": 0.6467259498787389,
      "grad_norm": 0.5451711416244507,
      "learning_rate": 0.0001964660077867625,
      "loss": 0.6599,
      "step": 2400
    },
    {
      "epoch": 0.6736728644570197,
      "grad_norm": 0.5337641835212708,
      "learning_rate": 0.00018149146451033245,
      "loss": 0.6558,
      "step": 2500
    },
    {
      "epoch": 0.7006197790353005,
      "grad_norm": 0.482284814119339,
      "learning_rate": 0.00016651692123390236,
      "loss": 0.6498,
      "step": 2600
    },
    {
      "epoch": 0.7275666936135813,
      "grad_norm": 0.4677334129810333,
      "learning_rate": 0.0001515423779574723,
      "loss": 0.6469,
      "step": 2700
    },
    {
      "epoch": 0.7545136081918621,
      "grad_norm": 0.4620131850242615,
      "learning_rate": 0.00013656783468104223,
      "loss": 0.6438,
      "step": 2800
    },
    {
      "epoch": 0.7814605227701428,
      "grad_norm": 0.5942940711975098,
      "learning_rate": 0.00012159329140461216,
      "loss": 0.6392,
      "step": 2900
    },
    {
      "epoch": 0.8084074373484236,
      "grad_norm": 0.4553832709789276,
      "learning_rate": 0.00010661874812818209,
      "loss": 0.6377,
      "step": 3000
    },
    {
      "epoch": 0.8353543519267044,
      "grad_norm": 0.40645596385002136,
      "learning_rate": 9.164420485175202e-05,
      "loss": 0.6337,
      "step": 3100
    },
    {
      "epoch": 0.8623012665049852,
      "grad_norm": 0.47877421975135803,
      "learning_rate": 7.666966157532196e-05,
      "loss": 0.6316,
      "step": 3200
    },
    {
      "epoch": 0.889248181083266,
      "grad_norm": 0.45453280210494995,
      "learning_rate": 6.169511829889188e-05,
      "loss": 0.6289,
      "step": 3300
    },
    {
      "epoch": 0.9161950956615468,
      "grad_norm": 0.4047424793243408,
      "learning_rate": 4.6720575022461816e-05,
      "loss": 0.6273,
      "step": 3400
    },
    {
      "epoch": 0.9431420102398276,
      "grad_norm": 0.37653082609176636,
      "learning_rate": 3.1746031746031745e-05,
      "loss": 0.6251,
      "step": 3500
    },
    {
      "epoch": 0.9700889248181084,
      "grad_norm": 0.4033695161342621,
      "learning_rate": 1.6771488469601677e-05,
      "loss": 0.6241,
      "step": 3600
    },
    {
      "epoch": 0.9970358393963891,
      "grad_norm": 0.34868648648262024,
      "learning_rate": 1.7969451931716085e-06,
      "loss": 0.6244,
      "step": 3700
    },
    {
      "epoch": 1.0,
      "eval_loss": 0.5769700407981873,
      "eval_runtime": 4.9602,
      "eval_samples_per_second": 1008.034,
      "eval_steps_per_second": 15.927,
      "step": 3711
    }
  ],
  "logging_steps": 100,
  "max_steps": 3711,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 1422077952000000.0,
  "train_batch_size": 256,
  "trial_name": null,
  "trial_params": null
}
