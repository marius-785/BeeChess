{
  "best_global_step": 7422,
  "best_metric": 0.4943895637989044,
  "best_model_checkpoint": "./CPTkzer4/checkpoint-7422",
  "epoch": 2.0,
  "eval_steps": 500,
  "global_step": 7422,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.026946914578280787,
      "grad_norm": 2.1376681327819824,
      "learning_rate": 3.3333333333333335e-05,
      "loss": 4.0497,
      "step": 100
    },
    {
      "epoch": 0.05389382915656157,
      "grad_norm": 1.947095513343811,
      "learning_rate": 6.700336700336701e-05,
      "loss": 3.1891,
      "step": 200
    },
    {
      "epoch": 0.08084074373484236,
      "grad_norm": 1.0270919799804688,
      "learning_rate": 0.00010067340067340068,
      "loss": 2.6106,
      "step": 300
    },
    {
      "epoch": 0.10778765831312315,
      "grad_norm": 2.2978007793426514,
      "learning_rate": 0.00013434343434343436,
      "loss": 2.2148,
      "step": 400
    },
    {
      "epoch": 0.13473457289140395,
      "grad_norm": 2.3600921630859375,
      "learning_rate": 0.00016801346801346802,
      "loss": 2.0157,
      "step": 500
    },
    {
      "epoch": 0.16168148746968472,
      "grad_norm": 1.5277516841888428,
      "learning_rate": 0.00020168350168350168,
      "loss": 1.8514,
      "step": 600
    },
    {
      "epoch": 0.18862840204796552,
      "grad_norm": 0.9693588018417358,
      "learning_rate": 0.00023535353535353534,
      "loss": 1.6752,
      "step": 700
    },
    {
      "epoch": 0.2155753166262463,
      "grad_norm": 1.0415146350860596,
      "learning_rate": 0.000269023569023569,
      "loss": 1.467,
      "step": 800
    },
    {
      "epoch": 0.2425222312045271,
      "grad_norm": 0.6905006170272827,
      "learning_rate": 0.0003026936026936027,
      "loss": 1.2917,
      "step": 900
    },
    {
      "epoch": 0.2694691457828079,
      "grad_norm": 0.8121784925460815,
      "learning_rate": 0.0003363636363636364,
      "loss": 1.1733,
      "step": 1000
    },
    {
      "epoch": 0.29641606036108864,
      "grad_norm": 0.8420361876487732,
      "learning_rate": 0.00037003367003367007,
      "loss": 1.0849,
      "step": 1100
    },
    {
      "epoch": 0.32336297493936944,
      "grad_norm": 0.9475439190864563,
      "learning_rate": 0.00040370370370370375,
      "loss": 0.9815,
      "step": 1200
    },
    {
      "epoch": 0.35030988951765024,
      "grad_norm": 0.6451847553253174,
      "learning_rate": 0.0004373737373737374,
      "loss": 0.9041,
      "step": 1300
    },
    {
      "epoch": 0.37725680409593104,
      "grad_norm": 0.6759201288223267,
      "learning_rate": 0.0004710437710437711,
      "loss": 0.8537,
      "step": 1400
    },
    {
      "epoch": 0.4042037186742118,
      "grad_norm": 0.711258590221405,
      "learning_rate": 0.0004994760086832847,
      "loss": 0.8187,
      "step": 1500
    },
    {
      "epoch": 0.4311506332524926,
      "grad_norm": 0.6480525135993958,
      "learning_rate": 0.0004957332135638895,
      "loss": 0.7885,
      "step": 1600
    },
    {
      "epoch": 0.4580975478307734,
      "grad_norm": 0.7594190835952759,
      "learning_rate": 0.0004919904184444944,
      "loss": 0.7623,
      "step": 1700
    },
    {
      "epoch": 0.4850444624090542,
      "grad_norm": 0.6151254177093506,
      "learning_rate": 0.0004882476233250992,
      "loss": 0.7379,
      "step": 1800
    },
    {
      "epoch": 0.511991376987335,
      "grad_norm": 0.547523558139801,
      "learning_rate": 0.000484504828205704,
      "loss": 0.7194,
      "step": 1900
    },
    {
      "epoch": 0.5389382915656158,
      "grad_norm": 0.49036794900894165,
      "learning_rate": 0.0004807620330863089,
      "loss": 0.7042,
      "step": 2000
    },
    {
      "epoch": 0.5658852061438965,
      "grad_norm": 0.5612591505050659,
      "learning_rate": 0.0004770192379669137,
      "loss": 0.6933,
      "step": 2100
    },
    {
      "epoch": 0.5928321207221773,
      "grad_norm": 0.5077720284461975,
      "learning_rate": 0.00047327644284751854,
      "loss": 0.6824,
      "step": 2200
    },
    {
      "epoch": 0.6197790353004581,
      "grad_norm": 0.4577786922454834,
      "learning_rate": 0.00046953364772812337,
      "loss": 0.6737,
      "step": 2300
    },
    {
      "epoch": 0.6467259498787389,
      "grad_norm": 0.4633905291557312,
      "learning_rate": 0.00046579085260872825,
      "loss": 0.6647,
      "step": 2400
    },
    {
      "epoch": 0.6736728644570197,
      "grad_norm": 0.45693710446357727,
      "learning_rate": 0.000462048057489333,
      "loss": 0.6588,
      "step": 2500
    },
    {
      "epoch": 0.7006197790353005,
      "grad_norm": 0.43512848019599915,
      "learning_rate": 0.00045830526236993784,
      "loss": 0.6507,
      "step": 2600
    },
    {
      "epoch": 0.7275666936135813,
      "grad_norm": 0.42892107367515564,
      "learning_rate": 0.0004545624672505427,
      "loss": 0.6456,
      "step": 2700
    },
    {
      "epoch": 0.7545136081918621,
      "grad_norm": 0.41974401473999023,
      "learning_rate": 0.00045081967213114754,
      "loss": 0.6406,
      "step": 2800
    },
    {
      "epoch": 0.7814605227701428,
      "grad_norm": 0.43213531374931335,
      "learning_rate": 0.00044707687701175236,
      "loss": 0.6344,
      "step": 2900
    },
    {
      "epoch": 0.8084074373484236,
      "grad_norm": 0.5155136585235596,
      "learning_rate": 0.00044333408189235724,
      "loss": 0.6307,
      "step": 3000
    },
    {
      "epoch": 0.8353543519267044,
      "grad_norm": 0.44237565994262695,
      "learning_rate": 0.00043959128677296207,
      "loss": 0.6245,
      "step": 3100
    },
    {
      "epoch": 0.8623012665049852,
      "grad_norm": 0.4411505162715912,
      "learning_rate": 0.0004358484916535669,
      "loss": 0.6207,
      "step": 3200
    },
    {
      "epoch": 0.889248181083266,
      "grad_norm": 0.42737528681755066,
      "learning_rate": 0.00043210569653417177,
      "loss": 0.6164,
      "step": 3300
    },
    {
      "epoch": 0.9161950956615468,
      "grad_norm": 0.45602837204933167,
      "learning_rate": 0.0004283629014147766,
      "loss": 0.6122,
      "step": 3400
    },
    {
      "epoch": 0.9431420102398276,
      "grad_norm": 0.40537795424461365,
      "learning_rate": 0.0004246201062953814,
      "loss": 0.6088,
      "step": 3500
    },
    {
      "epoch": 0.9700889248181084,
      "grad_norm": 0.40019696950912476,
      "learning_rate": 0.0004208773111759862,
      "loss": 0.605,
      "step": 3600
    },
    {
      "epoch": 0.9970358393963891,
      "grad_norm": 0.40433862805366516,
      "learning_rate": 0.00041713451605659106,
      "loss": 0.6031,
      "step": 3700
    },
    {
      "epoch": 1.0,
      "eval_loss": 0.5489723086357117,
      "eval_runtime": 4.2097,
      "eval_samples_per_second": 1187.719,
      "eval_steps_per_second": 18.766,
      "step": 3711
    },
    {
      "epoch": 1.02398275397467,
      "grad_norm": 0.39370110630989075,
      "learning_rate": 0.0004133917209371959,
      "loss": 0.5993,
      "step": 3800
    },
    {
      "epoch": 1.0509296685529508,
      "grad_norm": 0.38050445914268494,
      "learning_rate": 0.0004096489258178007,
      "loss": 0.5951,
      "step": 3900
    },
    {
      "epoch": 1.0778765831312316,
      "grad_norm": 0.4112318456172943,
      "learning_rate": 0.0004059061306984056,
      "loss": 0.5931,
      "step": 4000
    },
    {
      "epoch": 1.1048234977095122,
      "grad_norm": 0.3658769726753235,
      "learning_rate": 0.0004021633355790104,
      "loss": 0.5908,
      "step": 4100
    },
    {
      "epoch": 1.131770412287793,
      "grad_norm": 0.37259042263031006,
      "learning_rate": 0.00039842054045961524,
      "loss": 0.5875,
      "step": 4200
    },
    {
      "epoch": 1.1587173268660738,
      "grad_norm": 0.37288033962249756,
      "learning_rate": 0.0003946777453402201,
      "loss": 0.5846,
      "step": 4300
    },
    {
      "epoch": 1.1856642414443546,
      "grad_norm": 0.3596794903278351,
      "learning_rate": 0.00039093495022082494,
      "loss": 0.582,
      "step": 4400
    },
    {
      "epoch": 1.2126111560226354,
      "grad_norm": 0.38653820753097534,
      "learning_rate": 0.00038719215510142976,
      "loss": 0.5797,
      "step": 4500
    },
    {
      "epoch": 1.2395580706009162,
      "grad_norm": 0.41016849875450134,
      "learning_rate": 0.00038344935998203464,
      "loss": 0.5787,
      "step": 4600
    },
    {
      "epoch": 1.266504985179197,
      "grad_norm": 0.37867361307144165,
      "learning_rate": 0.0003797065648626394,
      "loss": 0.5763,
      "step": 4700
    },
    {
      "epoch": 1.2934518997574778,
      "grad_norm": 0.34333595633506775,
      "learning_rate": 0.00037596376974324423,
      "loss": 0.5743,
      "step": 4800
    },
    {
      "epoch": 1.3203988143357586,
      "grad_norm": 0.3676395118236542,
      "learning_rate": 0.00037222097462384906,
      "loss": 0.5715,
      "step": 4900
    },
    {
      "epoch": 1.3473457289140394,
      "grad_norm": 0.33837345242500305,
      "learning_rate": 0.00036847817950445394,
      "loss": 0.5711,
      "step": 5000
    },
    {
      "epoch": 1.3742926434923202,
      "grad_norm": 0.3484857678413391,
      "learning_rate": 0.00036473538438505876,
      "loss": 0.5693,
      "step": 5100
    },
    {
      "epoch": 1.401239558070601,
      "grad_norm": 0.37282976508140564,
      "learning_rate": 0.0003609925892656636,
      "loss": 0.5662,
      "step": 5200
    },
    {
      "epoch": 1.4281864726488818,
      "grad_norm": 0.35651910305023193,
      "learning_rate": 0.00035724979414626846,
      "loss": 0.5651,
      "step": 5300
    },
    {
      "epoch": 1.4551333872271626,
      "grad_norm": 0.3937932550907135,
      "learning_rate": 0.0003535069990268733,
      "loss": 0.5628,
      "step": 5400
    },
    {
      "epoch": 1.4820803018054431,
      "grad_norm": 0.35407814383506775,
      "learning_rate": 0.0003497642039074781,
      "loss": 0.5617,
      "step": 5500
    },
    {
      "epoch": 1.509027216383724,
      "grad_norm": 0.3739895224571228,
      "learning_rate": 0.000346021408788083,
      "loss": 0.5603,
      "step": 5600
    },
    {
      "epoch": 1.5359741309620047,
      "grad_norm": 0.33900636434555054,
      "learning_rate": 0.0003422786136686878,
      "loss": 0.558,
      "step": 5700
    },
    {
      "epoch": 1.5629210455402855,
      "grad_norm": 0.3704738914966583,
      "learning_rate": 0.0003385358185492926,
      "loss": 0.557,
      "step": 5800
    },
    {
      "epoch": 1.5898679601185663,
      "grad_norm": 0.35645225644111633,
      "learning_rate": 0.00033479302342989746,
      "loss": 0.5556,
      "step": 5900
    },
    {
      "epoch": 1.6168148746968471,
      "grad_norm": 0.41405820846557617,
      "learning_rate": 0.0003310502283105023,
      "loss": 0.5545,
      "step": 6000
    },
    {
      "epoch": 1.643761789275128,
      "grad_norm": 0.35945025086402893,
      "learning_rate": 0.0003273074331911071,
      "loss": 0.5524,
      "step": 6100
    },
    {
      "epoch": 1.6707087038534087,
      "grad_norm": 0.3624177873134613,
      "learning_rate": 0.00032356463807171193,
      "loss": 0.5517,
      "step": 6200
    },
    {
      "epoch": 1.6976556184316896,
      "grad_norm": 0.35229575634002686,
      "learning_rate": 0.0003198218429523168,
      "loss": 0.5503,
      "step": 6300
    },
    {
      "epoch": 1.7246025330099704,
      "grad_norm": 0.3421778380870819,
      "learning_rate": 0.00031607904783292163,
      "loss": 0.5491,
      "step": 6400
    },
    {
      "epoch": 1.7515494475882512,
      "grad_norm": 0.34820204973220825,
      "learning_rate": 0.00031233625271352646,
      "loss": 0.5465,
      "step": 6500
    },
    {
      "epoch": 1.778496362166532,
      "grad_norm": 0.3759932816028595,
      "learning_rate": 0.00030859345759413133,
      "loss": 0.5463,
      "step": 6600
    },
    {
      "epoch": 1.8054432767448128,
      "grad_norm": 0.36243870854377747,
      "learning_rate": 0.00030485066247473616,
      "loss": 0.5455,
      "step": 6700
    },
    {
      "epoch": 1.8323901913230936,
      "grad_norm": 0.317886620759964,
      "learning_rate": 0.000301107867355341,
      "loss": 0.5445,
      "step": 6800
    },
    {
      "epoch": 1.8593371059013744,
      "grad_norm": 0.363844633102417,
      "learning_rate": 0.00029736507223594586,
      "loss": 0.5431,
      "step": 6900
    },
    {
      "epoch": 1.8862840204796552,
      "grad_norm": 0.36852315068244934,
      "learning_rate": 0.00029362227711655063,
      "loss": 0.5423,
      "step": 7000
    },
    {
      "epoch": 1.913230935057936,
      "grad_norm": 0.37710216641426086,
      "learning_rate": 0.00028987948199715545,
      "loss": 0.5418,
      "step": 7100
    },
    {
      "epoch": 1.9401778496362168,
      "grad_norm": 0.3210100829601288,
      "learning_rate": 0.00028613668687776033,
      "loss": 0.5401,
      "step": 7200
    },
    {
      "epoch": 1.9671247642144976,
      "grad_norm": 0.3434917628765106,
      "learning_rate": 0.00028239389175836515,
      "loss": 0.5392,
      "step": 7300
    },
    {
      "epoch": 1.9940716787927784,
      "grad_norm": 0.33222612738609314,
      "learning_rate": 0.00027865109663897,
      "loss": 0.5378,
      "step": 7400
    },
    {
      "epoch": 2.0,
      "eval_loss": 0.4943895637989044,
      "eval_runtime": 4.1894,
      "eval_samples_per_second": 1193.484,
      "eval_steps_per_second": 18.857,
      "step": 7422
    }
  ],
  "logging_steps": 100,
  "max_steps": 14844,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 4,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 1931280384000000.0,
  "train_batch_size": 256,
  "trial_name": null,
  "trial_params": null
}
