{
  "best_global_step": 11133,
  "best_metric": 0.4731209874153137,
  "best_model_checkpoint": "./CPTkzer4/checkpoint-11133",
  "epoch": 3.0,
  "eval_steps": 500,
  "global_step": 11133,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.026946914578280787,
      "grad_norm": 2.1376681327819824,
      "learning_rate": 3.3333333333333335e-05,
      "loss": 4.0497,
      "step": 100
    },
    {
      "epoch": 0.05389382915656157,
      "grad_norm": 1.947095513343811,
      "learning_rate": 6.700336700336701e-05,
      "loss": 3.1891,
      "step": 200
    },
    {
      "epoch": 0.08084074373484236,
      "grad_norm": 1.0270919799804688,
      "learning_rate": 0.00010067340067340068,
      "loss": 2.6106,
      "step": 300
    },
    {
      "epoch": 0.10778765831312315,
      "grad_norm": 2.2978007793426514,
      "learning_rate": 0.00013434343434343436,
      "loss": 2.2148,
      "step": 400
    },
    {
      "epoch": 0.13473457289140395,
      "grad_norm": 2.3600921630859375,
      "learning_rate": 0.00016801346801346802,
      "loss": 2.0157,
      "step": 500
    },
    {
      "epoch": 0.16168148746968472,
      "grad_norm": 1.5277516841888428,
      "learning_rate": 0.00020168350168350168,
      "loss": 1.8514,
      "step": 600
    },
    {
      "epoch": 0.18862840204796552,
      "grad_norm": 0.9693588018417358,
      "learning_rate": 0.00023535353535353534,
      "loss": 1.6752,
      "step": 700
    },
    {
      "epoch": 0.2155753166262463,
      "grad_norm": 1.0415146350860596,
      "learning_rate": 0.000269023569023569,
      "loss": 1.467,
      "step": 800
    },
    {
      "epoch": 0.2425222312045271,
      "grad_norm": 0.6905006170272827,
      "learning_rate": 0.0003026936026936027,
      "loss": 1.2917,
      "step": 900
    },
    {
      "epoch": 0.2694691457828079,
      "grad_norm": 0.8121784925460815,
      "learning_rate": 0.0003363636363636364,
      "loss": 1.1733,
      "step": 1000
    },
    {
      "epoch": 0.29641606036108864,
      "grad_norm": 0.8420361876487732,
      "learning_rate": 0.00037003367003367007,
      "loss": 1.0849,
      "step": 1100
    },
    {
      "epoch": 0.32336297493936944,
      "grad_norm": 0.9475439190864563,
      "learning_rate": 0.00040370370370370375,
      "loss": 0.9815,
      "step": 1200
    },
    {
      "epoch": 0.35030988951765024,
      "grad_norm": 0.6451847553253174,
      "learning_rate": 0.0004373737373737374,
      "loss": 0.9041,
      "step": 1300
    },
    {
      "epoch": 0.37725680409593104,
      "grad_norm": 0.6759201288223267,
      "learning_rate": 0.0004710437710437711,
      "loss": 0.8537,
      "step": 1400
    },
    {
      "epoch": 0.4042037186742118,
      "grad_norm": 0.711258590221405,
      "learning_rate": 0.0004994760086832847,
      "loss": 0.8187,
      "step": 1500
    },
    {
      "epoch": 0.4311506332524926,
      "grad_norm": 0.6480525135993958,
      "learning_rate": 0.0004957332135638895,
      "loss": 0.7885,
      "step": 1600
    },
    {
      "epoch": 0.4580975478307734,
      "grad_norm": 0.7594190835952759,
      "learning_rate": 0.0004919904184444944,
      "loss": 0.7623,
      "step": 1700
    },
    {
      "epoch": 0.4850444624090542,
      "grad_norm": 0.6151254177093506,
      "learning_rate": 0.0004882476233250992,
      "loss": 0.7379,
      "step": 1800
    },
    {
      "epoch": 0.511991376987335,
      "grad_norm": 0.547523558139801,
      "learning_rate": 0.000484504828205704,
      "loss": 0.7194,
      "step": 1900
    },
    {
      "epoch": 0.5389382915656158,
      "grad_norm": 0.49036794900894165,
      "learning_rate": 0.0004807620330863089,
      "loss": 0.7042,
      "step": 2000
    },
    {
      "epoch": 0.5658852061438965,
      "grad_norm": 0.5612591505050659,
      "learning_rate": 0.0004770192379669137,
      "loss": 0.6933,
      "step": 2100
    },
    {
      "epoch": 0.5928321207221773,
      "grad_norm": 0.5077720284461975,
      "learning_rate": 0.00047327644284751854,
      "loss": 0.6824,
      "step": 2200
    },
    {
      "epoch": 0.6197790353004581,
      "grad_norm": 0.4577786922454834,
      "learning_rate": 0.00046953364772812337,
      "loss": 0.6737,
      "step": 2300
    },
    {
      "epoch": 0.6467259498787389,
      "grad_norm": 0.4633905291557312,
      "learning_rate": 0.00046579085260872825,
      "loss": 0.6647,
      "step": 2400
    },
    {
      "epoch": 0.6736728644570197,
      "grad_norm": 0.45693710446357727,
      "learning_rate": 0.000462048057489333,
      "loss": 0.6588,
      "step": 2500
    },
    {
      "epoch": 0.7006197790353005,
      "grad_norm": 0.43512848019599915,
      "learning_rate": 0.00045830526236993784,
      "loss": 0.6507,
      "step": 2600
    },
    {
      "epoch": 0.7275666936135813,
      "grad_norm": 0.42892107367515564,
      "learning_rate": 0.0004545624672505427,
      "loss": 0.6456,
      "step": 2700
    },
    {
      "epoch": 0.7545136081918621,
      "grad_norm": 0.41974401473999023,
      "learning_rate": 0.00045081967213114754,
      "loss": 0.6406,
      "step": 2800
    },
    {
      "epoch": 0.7814605227701428,
      "grad_norm": 0.43213531374931335,
      "learning_rate": 0.00044707687701175236,
      "loss": 0.6344,
      "step": 2900
    },
    {
      "epoch": 0.8084074373484236,
      "grad_norm": 0.5155136585235596,
      "learning_rate": 0.00044333408189235724,
      "loss": 0.6307,
      "step": 3000
    },
    {
      "epoch": 0.8353543519267044,
      "grad_norm": 0.44237565994262695,
      "learning_rate": 0.00043959128677296207,
      "loss": 0.6245,
      "step": 3100
    },
    {
      "epoch": 0.8623012665049852,
      "grad_norm": 0.4411505162715912,
      "learning_rate": 0.0004358484916535669,
      "loss": 0.6207,
      "step": 3200
    },
    {
      "epoch": 0.889248181083266,
      "grad_norm": 0.42737528681755066,
      "learning_rate": 0.00043210569653417177,
      "loss": 0.6164,
      "step": 3300
    },
    {
      "epoch": 0.9161950956615468,
      "grad_norm": 0.45602837204933167,
      "learning_rate": 0.0004283629014147766,
      "loss": 0.6122,
      "step": 3400
    },
    {
      "epoch": 0.9431420102398276,
      "grad_norm": 0.40537795424461365,
      "learning_rate": 0.0004246201062953814,
      "loss": 0.6088,
      "step": 3500
    },
    {
      "epoch": 0.9700889248181084,
      "grad_norm": 0.40019696950912476,
      "learning_rate": 0.0004208773111759862,
      "loss": 0.605,
      "step": 3600
    },
    {
      "epoch": 0.9970358393963891,
      "grad_norm": 0.40433862805366516,
      "learning_rate": 0.00041713451605659106,
      "loss": 0.6031,
      "step": 3700
    },
    {
      "epoch": 1.0,
      "eval_loss": 0.5489723086357117,
      "eval_runtime": 4.2097,
      "eval_samples_per_second": 1187.719,
      "eval_steps_per_second": 18.766,
      "step": 3711
    },
    {
      "epoch": 1.02398275397467,
      "grad_norm": 0.39370110630989075,
      "learning_rate": 0.0004133917209371959,
      "loss": 0.5993,
      "step": 3800
    },
    {
      "epoch": 1.0509296685529508,
      "grad_norm": 0.38050445914268494,
      "learning_rate": 0.0004096489258178007,
      "loss": 0.5951,
      "step": 3900
    },
    {
      "epoch": 1.0778765831312316,
      "grad_norm": 0.4112318456172943,
      "learning_rate": 0.0004059061306984056,
      "loss": 0.5931,
      "step": 4000
    },
    {
      "epoch": 1.1048234977095122,
      "grad_norm": 0.3658769726753235,
      "learning_rate": 0.0004021633355790104,
      "loss": 0.5908,
      "step": 4100
    },
    {
      "epoch": 1.131770412287793,
      "grad_norm": 0.37259042263031006,
      "learning_rate": 0.00039842054045961524,
      "loss": 0.5875,
      "step": 4200
    },
    {
      "epoch": 1.1587173268660738,
      "grad_norm": 0.37288033962249756,
      "learning_rate": 0.0003946777453402201,
      "loss": 0.5846,
      "step": 4300
    },
    {
      "epoch": 1.1856642414443546,
      "grad_norm": 0.3596794903278351,
      "learning_rate": 0.00039093495022082494,
      "loss": 0.582,
      "step": 4400
    },
    {
      "epoch": 1.2126111560226354,
      "grad_norm": 0.38653820753097534,
      "learning_rate": 0.00038719215510142976,
      "loss": 0.5797,
      "step": 4500
    },
    {
      "epoch": 1.2395580706009162,
      "grad_norm": 0.41016849875450134,
      "learning_rate": 0.00038344935998203464,
      "loss": 0.5787,
      "step": 4600
    },
    {
      "epoch": 1.266504985179197,
      "grad_norm": 0.37867361307144165,
      "learning_rate": 0.0003797065648626394,
      "loss": 0.5763,
      "step": 4700
    },
    {
      "epoch": 1.2934518997574778,
      "grad_norm": 0.34333595633506775,
      "learning_rate": 0.00037596376974324423,
      "loss": 0.5743,
      "step": 4800
    },
    {
      "epoch": 1.3203988143357586,
      "grad_norm": 0.3676395118236542,
      "learning_rate": 0.00037222097462384906,
      "loss": 0.5715,
      "step": 4900
    },
    {
      "epoch": 1.3473457289140394,
      "grad_norm": 0.33837345242500305,
      "learning_rate": 0.00036847817950445394,
      "loss": 0.5711,
      "step": 5000
    },
    {
      "epoch": 1.3742926434923202,
      "grad_norm": 0.3484857678413391,
      "learning_rate": 0.00036473538438505876,
      "loss": 0.5693,
      "step": 5100
    },
    {
      "epoch": 1.401239558070601,
      "grad_norm": 0.37282976508140564,
      "learning_rate": 0.0003609925892656636,
      "loss": 0.5662,
      "step": 5200
    },
    {
      "epoch": 1.4281864726488818,
      "grad_norm": 0.35651910305023193,
      "learning_rate": 0.00035724979414626846,
      "loss": 0.5651,
      "step": 5300
    },
    {
      "epoch": 1.4551333872271626,
      "grad_norm": 0.3937932550907135,
      "learning_rate": 0.0003535069990268733,
      "loss": 0.5628,
      "step": 5400
    },
    {
      "epoch": 1.4820803018054431,
      "grad_norm": 0.35407814383506775,
      "learning_rate": 0.0003497642039074781,
      "loss": 0.5617,
      "step": 5500
    },
    {
      "epoch": 1.509027216383724,
      "grad_norm": 0.3739895224571228,
      "learning_rate": 0.000346021408788083,
      "loss": 0.5603,
      "step": 5600
    },
    {
      "epoch": 1.5359741309620047,
      "grad_norm": 0.33900636434555054,
      "learning_rate": 0.0003422786136686878,
      "loss": 0.558,
      "step": 5700
    },
    {
      "epoch": 1.5629210455402855,
      "grad_norm": 0.3704738914966583,
      "learning_rate": 0.0003385358185492926,
      "loss": 0.557,
      "step": 5800
    },
    {
      "epoch": 1.5898679601185663,
      "grad_norm": 0.35645225644111633,
      "learning_rate": 0.00033479302342989746,
      "loss": 0.5556,
      "step": 5900
    },
    {
      "epoch": 1.6168148746968471,
      "grad_norm": 0.41405820846557617,
      "learning_rate": 0.0003310502283105023,
      "loss": 0.5545,
      "step": 6000
    },
    {
      "epoch": 1.643761789275128,
      "grad_norm": 0.35945025086402893,
      "learning_rate": 0.0003273074331911071,
      "loss": 0.5524,
      "step": 6100
    },
    {
      "epoch": 1.6707087038534087,
      "grad_norm": 0.3624177873134613,
      "learning_rate": 0.00032356463807171193,
      "loss": 0.5517,
      "step": 6200
    },
    {
      "epoch": 1.6976556184316896,
      "grad_norm": 0.35229575634002686,
      "learning_rate": 0.0003198218429523168,
      "loss": 0.5503,
      "step": 6300
    },
    {
      "epoch": 1.7246025330099704,
      "grad_norm": 0.3421778380870819,
      "learning_rate": 0.00031607904783292163,
      "loss": 0.5491,
      "step": 6400
    },
    {
      "epoch": 1.7515494475882512,
      "grad_norm": 0.34820204973220825,
      "learning_rate": 0.00031233625271352646,
      "loss": 0.5465,
      "step": 6500
    },
    {
      "epoch": 1.778496362166532,
      "grad_norm": 0.3759932816028595,
      "learning_rate": 0.00030859345759413133,
      "loss": 0.5463,
      "step": 6600
    },
    {
      "epoch": 1.8054432767448128,
      "grad_norm": 0.36243870854377747,
      "learning_rate": 0.00030485066247473616,
      "loss": 0.5455,
      "step": 6700
    },
    {
      "epoch": 1.8323901913230936,
      "grad_norm": 0.317886620759964,
      "learning_rate": 0.000301107867355341,
      "loss": 0.5445,
      "step": 6800
    },
    {
      "epoch": 1.8593371059013744,
      "grad_norm": 0.363844633102417,
      "learning_rate": 0.00029736507223594586,
      "loss": 0.5431,
      "step": 6900
    },
    {
      "epoch": 1.8862840204796552,
      "grad_norm": 0.36852315068244934,
      "learning_rate": 0.00029362227711655063,
      "loss": 0.5423,
      "step": 7000
    },
    {
      "epoch": 1.913230935057936,
      "grad_norm": 0.37710216641426086,
      "learning_rate": 0.00028987948199715545,
      "loss": 0.5418,
      "step": 7100
    },
    {
      "epoch": 1.9401778496362168,
      "grad_norm": 0.3210100829601288,
      "learning_rate": 0.00028613668687776033,
      "loss": 0.5401,
      "step": 7200
    },
    {
      "epoch": 1.9671247642144976,
      "grad_norm": 0.3434917628765106,
      "learning_rate": 0.00028239389175836515,
      "loss": 0.5392,
      "step": 7300
    },
    {
      "epoch": 1.9940716787927784,
      "grad_norm": 0.33222612738609314,
      "learning_rate": 0.00027865109663897,
      "loss": 0.5378,
      "step": 7400
    },
    {
      "epoch": 2.0,
      "eval_loss": 0.4943895637989044,
      "eval_runtime": 4.1894,
      "eval_samples_per_second": 1193.484,
      "eval_steps_per_second": 18.857,
      "step": 7422
    },
    {
      "epoch": 2.021018593371059,
      "grad_norm": 0.3156156539916992,
      "learning_rate": 0.0002749083015195748,
      "loss": 0.5368,
      "step": 7500
    },
    {
      "epoch": 2.04796550794934,
      "grad_norm": 0.31848275661468506,
      "learning_rate": 0.0002711655064001797,
      "loss": 0.5361,
      "step": 7600
    },
    {
      "epoch": 2.0749124225276208,
      "grad_norm": 0.3120485842227936,
      "learning_rate": 0.0002674227112807845,
      "loss": 0.5352,
      "step": 7700
    },
    {
      "epoch": 2.1018593371059016,
      "grad_norm": 0.3050265610218048,
      "learning_rate": 0.00026367991616138933,
      "loss": 0.5343,
      "step": 7800
    },
    {
      "epoch": 2.1288062516841824,
      "grad_norm": 0.32640790939331055,
      "learning_rate": 0.0002599371210419942,
      "loss": 0.5341,
      "step": 7900
    },
    {
      "epoch": 2.155753166262463,
      "grad_norm": 0.35795721411705017,
      "learning_rate": 0.00025619432592259903,
      "loss": 0.533,
      "step": 8000
    },
    {
      "epoch": 2.1827000808407435,
      "grad_norm": 0.35958340764045715,
      "learning_rate": 0.0002524515308032038,
      "loss": 0.5319,
      "step": 8100
    },
    {
      "epoch": 2.2096469954190243,
      "grad_norm": 0.3552267253398895,
      "learning_rate": 0.0002487087356838087,
      "loss": 0.5306,
      "step": 8200
    },
    {
      "epoch": 2.236593909997305,
      "grad_norm": 0.3274747133255005,
      "learning_rate": 0.0002449659405644135,
      "loss": 0.5295,
      "step": 8300
    },
    {
      "epoch": 2.263540824575586,
      "grad_norm": 0.3009008765220642,
      "learning_rate": 0.00024122314544501832,
      "loss": 0.5298,
      "step": 8400
    },
    {
      "epoch": 2.2904877391538667,
      "grad_norm": 0.3104633390903473,
      "learning_rate": 0.00023748035032562318,
      "loss": 0.5279,
      "step": 8500
    },
    {
      "epoch": 2.3174346537321475,
      "grad_norm": 0.3440876603126526,
      "learning_rate": 0.00023373755520622803,
      "loss": 0.5279,
      "step": 8600
    },
    {
      "epoch": 2.3443815683104283,
      "grad_norm": 0.3231814205646515,
      "learning_rate": 0.00022999476008683285,
      "loss": 0.527,
      "step": 8700
    },
    {
      "epoch": 2.371328482888709,
      "grad_norm": 0.34712618589401245,
      "learning_rate": 0.0002262519649674377,
      "loss": 0.5257,
      "step": 8800
    },
    {
      "epoch": 2.39827539746699,
      "grad_norm": 0.295894056558609,
      "learning_rate": 0.00022250916984804253,
      "loss": 0.5255,
      "step": 8900
    },
    {
      "epoch": 2.4252223120452707,
      "grad_norm": 0.3464893698692322,
      "learning_rate": 0.00021876637472864735,
      "loss": 0.5249,
      "step": 9000
    },
    {
      "epoch": 2.4521692266235515,
      "grad_norm": 0.3180166780948639,
      "learning_rate": 0.0002150235796092522,
      "loss": 0.5251,
      "step": 9100
    },
    {
      "epoch": 2.4791161412018323,
      "grad_norm": 0.32108086347579956,
      "learning_rate": 0.00021128078448985702,
      "loss": 0.5228,
      "step": 9200
    },
    {
      "epoch": 2.506063055780113,
      "grad_norm": 0.3482420742511749,
      "learning_rate": 0.00020753798937046187,
      "loss": 0.5222,
      "step": 9300
    },
    {
      "epoch": 2.533009970358394,
      "grad_norm": 0.3071948289871216,
      "learning_rate": 0.00020379519425106673,
      "loss": 0.5223,
      "step": 9400
    },
    {
      "epoch": 2.5599568849366747,
      "grad_norm": 0.33908236026763916,
      "learning_rate": 0.00020005239913167152,
      "loss": 0.5221,
      "step": 9500
    },
    {
      "epoch": 2.5869037995149555,
      "grad_norm": 0.3340666592121124,
      "learning_rate": 0.00019630960401227637,
      "loss": 0.5211,
      "step": 9600
    },
    {
      "epoch": 2.6138507140932363,
      "grad_norm": 0.3397683799266815,
      "learning_rate": 0.0001925668088928812,
      "loss": 0.5204,
      "step": 9700
    },
    {
      "epoch": 2.640797628671517,
      "grad_norm": 0.30849993228912354,
      "learning_rate": 0.00018882401377348605,
      "loss": 0.5203,
      "step": 9800
    },
    {
      "epoch": 2.667744543249798,
      "grad_norm": 0.3396831154823303,
      "learning_rate": 0.0001850812186540909,
      "loss": 0.5187,
      "step": 9900
    },
    {
      "epoch": 2.6946914578280787,
      "grad_norm": 0.31598541140556335,
      "learning_rate": 0.0001813384235346957,
      "loss": 0.5192,
      "step": 10000
    },
    {
      "epoch": 2.7216383724063595,
      "grad_norm": 0.32434919476509094,
      "learning_rate": 0.00017759562841530055,
      "loss": 0.5184,
      "step": 10100
    },
    {
      "epoch": 2.7485852869846403,
      "grad_norm": 0.35645923018455505,
      "learning_rate": 0.0001738528332959054,
      "loss": 0.5186,
      "step": 10200
    },
    {
      "epoch": 2.775532201562921,
      "grad_norm": 0.31675565242767334,
      "learning_rate": 0.00017011003817651022,
      "loss": 0.5175,
      "step": 10300
    },
    {
      "epoch": 2.802479116141202,
      "grad_norm": 0.31370946764945984,
      "learning_rate": 0.00016636724305711507,
      "loss": 0.5173,
      "step": 10400
    },
    {
      "epoch": 2.8294260307194827,
      "grad_norm": 0.32849663496017456,
      "learning_rate": 0.0001626244479377199,
      "loss": 0.5167,
      "step": 10500
    },
    {
      "epoch": 2.8563729452977635,
      "grad_norm": 0.32394444942474365,
      "learning_rate": 0.00015888165281832472,
      "loss": 0.5157,
      "step": 10600
    },
    {
      "epoch": 2.8833198598760443,
      "grad_norm": 0.3242620825767517,
      "learning_rate": 0.00015513885769892957,
      "loss": 0.5159,
      "step": 10700
    },
    {
      "epoch": 2.910266774454325,
      "grad_norm": 0.299594521522522,
      "learning_rate": 0.0001513960625795344,
      "loss": 0.5159,
      "step": 10800
    },
    {
      "epoch": 2.937213689032606,
      "grad_norm": 0.34088239073753357,
      "learning_rate": 0.00014765326746013925,
      "loss": 0.5141,
      "step": 10900
    },
    {
      "epoch": 2.9641606036108863,
      "grad_norm": 0.31799840927124023,
      "learning_rate": 0.00014391047234074407,
      "loss": 0.5138,
      "step": 11000
    },
    {
      "epoch": 2.9911075181891675,
      "grad_norm": 0.2934693694114685,
      "learning_rate": 0.0001401676772213489,
      "loss": 0.514,
      "step": 11100
    },
    {
      "epoch": 3.0,
      "eval_loss": 0.4731209874153137,
      "eval_runtime": 4.2063,
      "eval_samples_per_second": 1188.684,
      "eval_steps_per_second": 18.781,
      "step": 11133
    }
  ],
  "logging_steps": 100,
  "max_steps": 14844,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 4,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 2896920576000000.0,
  "train_batch_size": 256,
  "trial_name": null,
  "trial_params": null
}
