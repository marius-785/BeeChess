{
  "best_global_step": 7422,
  "best_metric": 0.5205816626548767,
  "best_model_checkpoint": "./CT11/checkpoint-7422",
  "epoch": 1.0,
  "eval_steps": 500,
  "global_step": 7422,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.013473457289140393,
      "grad_norm": 2.507375478744507,
      "learning_rate": 6.669361358124495e-06,
      "loss": 4.2734,
      "step": 100
    },
    {
      "epoch": 0.026946914578280787,
      "grad_norm": 2.2889797687530518,
      "learning_rate": 1.3406090002694691e-05,
      "loss": 3.7504,
      "step": 200
    },
    {
      "epoch": 0.04042037186742118,
      "grad_norm": 2.2192444801330566,
      "learning_rate": 2.0142818647264888e-05,
      "loss": 3.2701,
      "step": 300
    },
    {
      "epoch": 0.05389382915656157,
      "grad_norm": 1.9082268476486206,
      "learning_rate": 2.6879547291835086e-05,
      "loss": 2.9703,
      "step": 400
    },
    {
      "epoch": 0.06736728644570197,
      "grad_norm": 1.4878844022750854,
      "learning_rate": 3.361627593640528e-05,
      "loss": 2.7243,
      "step": 500
    },
    {
      "epoch": 0.08084074373484236,
      "grad_norm": 1.728318452835083,
      "learning_rate": 4.035300458097548e-05,
      "loss": 2.4958,
      "step": 600
    },
    {
      "epoch": 0.09431420102398276,
      "grad_norm": 1.9488646984100342,
      "learning_rate": 4.708973322554568e-05,
      "loss": 2.3056,
      "step": 700
    },
    {
      "epoch": 0.10778765831312315,
      "grad_norm": 1.8756595849990845,
      "learning_rate": 5.382646187011587e-05,
      "loss": 2.1734,
      "step": 800
    },
    {
      "epoch": 0.12126111560226355,
      "grad_norm": 1.5761357545852661,
      "learning_rate": 6.056319051468607e-05,
      "loss": 2.0717,
      "step": 900
    },
    {
      "epoch": 0.13473457289140395,
      "grad_norm": 2.49153470993042,
      "learning_rate": 6.729991915925626e-05,
      "loss": 1.9891,
      "step": 1000
    },
    {
      "epoch": 0.14820803018054432,
      "grad_norm": 1.8852348327636719,
      "learning_rate": 7.403664780382646e-05,
      "loss": 1.9029,
      "step": 1100
    },
    {
      "epoch": 0.16168148746968472,
      "grad_norm": 1.363437533378601,
      "learning_rate": 8.077337644839666e-05,
      "loss": 1.8189,
      "step": 1200
    },
    {
      "epoch": 0.17515494475882512,
      "grad_norm": 1.6729093790054321,
      "learning_rate": 8.751010509296686e-05,
      "loss": 1.7352,
      "step": 1300
    },
    {
      "epoch": 0.18862840204796552,
      "grad_norm": 1.3850228786468506,
      "learning_rate": 9.424683373753705e-05,
      "loss": 1.6603,
      "step": 1400
    },
    {
      "epoch": 0.2021018593371059,
      "grad_norm": 1.0432305335998535,
      "learning_rate": 0.00010098356238210725,
      "loss": 1.5764,
      "step": 1500
    },
    {
      "epoch": 0.2155753166262463,
      "grad_norm": 1.245720386505127,
      "learning_rate": 0.00010772029102667745,
      "loss": 1.4896,
      "step": 1600
    },
    {
      "epoch": 0.2290487739153867,
      "grad_norm": 1.2359944581985474,
      "learning_rate": 0.00011445701967124765,
      "loss": 1.4112,
      "step": 1700
    },
    {
      "epoch": 0.2425222312045271,
      "grad_norm": 1.5725252628326416,
      "learning_rate": 0.00012119374831581784,
      "loss": 1.3437,
      "step": 1800
    },
    {
      "epoch": 0.2559956884936675,
      "grad_norm": 1.1958653926849365,
      "learning_rate": 0.00012793047696038804,
      "loss": 1.2826,
      "step": 1900
    },
    {
      "epoch": 0.2694691457828079,
      "grad_norm": 1.208345651626587,
      "learning_rate": 0.00013466720560495823,
      "loss": 1.2278,
      "step": 2000
    },
    {
      "epoch": 0.28294260307194824,
      "grad_norm": 0.9795716404914856,
      "learning_rate": 0.00014140393424952845,
      "loss": 1.182,
      "step": 2100
    },
    {
      "epoch": 0.29641606036108864,
      "grad_norm": 1.027790904045105,
      "learning_rate": 0.00014814066289409864,
      "loss": 1.1424,
      "step": 2200
    },
    {
      "epoch": 0.30988951765022904,
      "grad_norm": 1.060271143913269,
      "learning_rate": 0.00015487739153866882,
      "loss": 1.1004,
      "step": 2300
    },
    {
      "epoch": 0.32336297493936944,
      "grad_norm": 1.0012234449386597,
      "learning_rate": 0.000161614120183239,
      "loss": 1.0605,
      "step": 2400
    },
    {
      "epoch": 0.33683643222850984,
      "grad_norm": 0.9243299961090088,
      "learning_rate": 0.0001683508488278092,
      "loss": 1.0095,
      "step": 2500
    },
    {
      "epoch": 0.35030988951765024,
      "grad_norm": 1.3422080278396606,
      "learning_rate": 0.00017508757747237942,
      "loss": 0.9558,
      "step": 2600
    },
    {
      "epoch": 0.36378334680679064,
      "grad_norm": 1.0578101873397827,
      "learning_rate": 0.0001818243061169496,
      "loss": 0.9083,
      "step": 2700
    },
    {
      "epoch": 0.37725680409593104,
      "grad_norm": 0.9041587710380554,
      "learning_rate": 0.00018856103476151982,
      "loss": 0.8759,
      "step": 2800
    },
    {
      "epoch": 0.3907302613850714,
      "grad_norm": 0.9087947607040405,
      "learning_rate": 0.00019529776340609,
      "loss": 0.849,
      "step": 2900
    },
    {
      "epoch": 0.4042037186742118,
      "grad_norm": 0.9010210633277893,
      "learning_rate": 0.00020203449205066022,
      "loss": 0.8254,
      "step": 3000
    },
    {
      "epoch": 0.4176771759633522,
      "grad_norm": 0.884867787361145,
      "learning_rate": 0.0002087712206952304,
      "loss": 0.8045,
      "step": 3100
    },
    {
      "epoch": 0.4311506332524926,
      "grad_norm": 0.8793580532073975,
      "learning_rate": 0.00021550794933980057,
      "loss": 0.7866,
      "step": 3200
    },
    {
      "epoch": 0.444624090541633,
      "grad_norm": 0.8135902881622314,
      "learning_rate": 0.0002222446779843708,
      "loss": 0.7712,
      "step": 3300
    },
    {
      "epoch": 0.4580975478307734,
      "grad_norm": 0.8412314653396606,
      "learning_rate": 0.00022898140662894098,
      "loss": 0.7575,
      "step": 3400
    },
    {
      "epoch": 0.4715710051199138,
      "grad_norm": 0.8157561421394348,
      "learning_rate": 0.0002357181352735112,
      "loss": 0.7449,
      "step": 3500
    },
    {
      "epoch": 0.4850444624090542,
      "grad_norm": 0.89199298620224,
      "learning_rate": 0.00024245486391808138,
      "loss": 0.7327,
      "step": 3600
    },
    {
      "epoch": 0.49851791969819453,
      "grad_norm": 0.749671995639801,
      "learning_rate": 0.00024919159256265157,
      "loss": 0.7236,
      "step": 3700
    },
    {
      "epoch": 0.511991376987335,
      "grad_norm": 0.7049354910850525,
      "learning_rate": 0.0002559283212072218,
      "loss": 0.7121,
      "step": 3800
    },
    {
      "epoch": 0.5254648342764754,
      "grad_norm": 0.7413152456283569,
      "learning_rate": 0.00026266504985179194,
      "loss": 0.7038,
      "step": 3900
    },
    {
      "epoch": 0.5389382915656158,
      "grad_norm": 0.8080446720123291,
      "learning_rate": 0.00026940177849636216,
      "loss": 0.6954,
      "step": 4000
    },
    {
      "epoch": 0.5524117488547561,
      "grad_norm": 0.6535927057266235,
      "learning_rate": 0.0002761385071409324,
      "loss": 0.6898,
      "step": 4100
    },
    {
      "epoch": 0.5658852061438965,
      "grad_norm": 0.7123827934265137,
      "learning_rate": 0.00028287523578550254,
      "loss": 0.6817,
      "step": 4200
    },
    {
      "epoch": 0.5793586634330369,
      "grad_norm": 0.6640825867652893,
      "learning_rate": 0.00028961196443007275,
      "loss": 0.6754,
      "step": 4300
    },
    {
      "epoch": 0.5928321207221773,
      "grad_norm": 0.6870656609535217,
      "learning_rate": 0.00029634869307464297,
      "loss": 0.6689,
      "step": 4400
    },
    {
      "epoch": 0.6063055780113177,
      "grad_norm": 0.6682552695274353,
      "learning_rate": 0.0003030854217192132,
      "loss": 0.6632,
      "step": 4500
    },
    {
      "epoch": 0.6197790353004581,
      "grad_norm": 0.7342257499694824,
      "learning_rate": 0.00030982215036378334,
      "loss": 0.6574,
      "step": 4600
    },
    {
      "epoch": 0.6332524925895985,
      "grad_norm": 0.6166369915008545,
      "learning_rate": 0.00031655887900835356,
      "loss": 0.6527,
      "step": 4700
    },
    {
      "epoch": 0.6467259498787389,
      "grad_norm": 0.6189355850219727,
      "learning_rate": 0.0003232956076529238,
      "loss": 0.6462,
      "step": 4800
    },
    {
      "epoch": 0.6601994071678793,
      "grad_norm": 0.6251354813575745,
      "learning_rate": 0.00033003233629749394,
      "loss": 0.6426,
      "step": 4900
    },
    {
      "epoch": 0.6736728644570197,
      "grad_norm": 0.6698986887931824,
      "learning_rate": 0.00033676906494206415,
      "loss": 0.6382,
      "step": 5000
    },
    {
      "epoch": 0.6871463217461601,
      "grad_norm": 0.6165614128112793,
      "learning_rate": 0.00034350579358663437,
      "loss": 0.6325,
      "step": 5100
    },
    {
      "epoch": 0.7006197790353005,
      "grad_norm": 0.6032245755195618,
      "learning_rate": 0.00035024252223120453,
      "loss": 0.6289,
      "step": 5200
    },
    {
      "epoch": 0.7140932363244409,
      "grad_norm": 0.6178377866744995,
      "learning_rate": 0.0003569792508757747,
      "loss": 0.6263,
      "step": 5300
    },
    {
      "epoch": 0.7275666936135813,
      "grad_norm": 0.5898728966712952,
      "learning_rate": 0.0003637159795203449,
      "loss": 0.6212,
      "step": 5400
    },
    {
      "epoch": 0.7410401509027217,
      "grad_norm": 0.5766586065292358,
      "learning_rate": 0.0003704527081649151,
      "loss": 0.6195,
      "step": 5500
    },
    {
      "epoch": 0.7545136081918621,
      "grad_norm": 0.562961757183075,
      "learning_rate": 0.00037718943680948533,
      "loss": 0.6149,
      "step": 5600
    },
    {
      "epoch": 0.7679870654810024,
      "grad_norm": 0.5768886804580688,
      "learning_rate": 0.0003839261654540555,
      "loss": 0.6104,
      "step": 5700
    },
    {
      "epoch": 0.7814605227701428,
      "grad_norm": 0.5576419830322266,
      "learning_rate": 0.0003906628940986257,
      "loss": 0.6071,
      "step": 5800
    },
    {
      "epoch": 0.7949339800592832,
      "grad_norm": 0.5863984823226929,
      "learning_rate": 0.0003973996227431959,
      "loss": 0.6049,
      "step": 5900
    },
    {
      "epoch": 0.8084074373484236,
      "grad_norm": 0.5108187794685364,
      "learning_rate": 0.0004041363513877661,
      "loss": 0.6014,
      "step": 6000
    },
    {
      "epoch": 0.821880894637564,
      "grad_norm": 0.49313387274742126,
      "learning_rate": 0.0004108730800323363,
      "loss": 0.5973,
      "step": 6100
    },
    {
      "epoch": 0.8353543519267044,
      "grad_norm": 0.5230685472488403,
      "learning_rate": 0.0004176098086769065,
      "loss": 0.5952,
      "step": 6200
    },
    {
      "epoch": 0.8488278092158448,
      "grad_norm": 0.49161818623542786,
      "learning_rate": 0.00042434653732147673,
      "loss": 0.5926,
      "step": 6300
    },
    {
      "epoch": 0.8623012665049852,
      "grad_norm": 0.4863325357437134,
      "learning_rate": 0.0004310832659660469,
      "loss": 0.5886,
      "step": 6400
    },
    {
      "epoch": 0.8757747237941256,
      "grad_norm": 0.5223461985588074,
      "learning_rate": 0.0004378199946106171,
      "loss": 0.5862,
      "step": 6500
    },
    {
      "epoch": 0.889248181083266,
      "grad_norm": 0.4890427589416504,
      "learning_rate": 0.0004445567232551873,
      "loss": 0.583,
      "step": 6600
    },
    {
      "epoch": 0.9027216383724064,
      "grad_norm": 0.5191927552223206,
      "learning_rate": 0.0004512934518997575,
      "loss": 0.5818,
      "step": 6700
    },
    {
      "epoch": 0.9161950956615468,
      "grad_norm": 0.49901819229125977,
      "learning_rate": 0.00045803018054432765,
      "loss": 0.5778,
      "step": 6800
    },
    {
      "epoch": 0.9296685529506872,
      "grad_norm": 0.45645302534103394,
      "learning_rate": 0.00046476690918889786,
      "loss": 0.5763,
      "step": 6900
    },
    {
      "epoch": 0.9431420102398276,
      "grad_norm": 0.45765361189842224,
      "learning_rate": 0.0004715036378334681,
      "loss": 0.5734,
      "step": 7000
    },
    {
      "epoch": 0.956615467528968,
      "grad_norm": 0.4579680562019348,
      "learning_rate": 0.00047824036647803824,
      "loss": 0.571,
      "step": 7100
    },
    {
      "epoch": 0.9700889248181084,
      "grad_norm": 0.509912371635437,
      "learning_rate": 0.00048497709512260845,
      "loss": 0.5691,
      "step": 7200
    },
    {
      "epoch": 0.9835623821072487,
      "grad_norm": 0.4724940061569214,
      "learning_rate": 0.0004917138237671787,
      "loss": 0.5679,
      "step": 7300
    },
    {
      "epoch": 0.9970358393963891,
      "grad_norm": 0.43843597173690796,
      "learning_rate": 0.0004984505524117488,
      "loss": 0.5657,
      "step": 7400
    },
    {
      "epoch": 1.0,
      "eval_loss": 0.5205816626548767,
      "eval_runtime": 4.3256,
      "eval_samples_per_second": 1155.922,
      "eval_steps_per_second": 18.264,
      "step": 7422
    }
  ],
  "logging_steps": 100,
  "max_steps": 74220,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 1361772134400000.0,
  "train_batch_size": 128,
  "trial_name": null,
  "trial_params": null
}
