{
  "best_global_step": 14844,
  "best_metric": 0.45925790071487427,
  "best_model_checkpoint": "./CT11/checkpoint-14844",
  "epoch": 2.0,
  "eval_steps": 500,
  "global_step": 14844,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.013473457289140393,
      "grad_norm": 2.507375478744507,
      "learning_rate": 6.669361358124495e-06,
      "loss": 4.2734,
      "step": 100
    },
    {
      "epoch": 0.026946914578280787,
      "grad_norm": 2.2889797687530518,
      "learning_rate": 1.3406090002694691e-05,
      "loss": 3.7504,
      "step": 200
    },
    {
      "epoch": 0.04042037186742118,
      "grad_norm": 2.2192444801330566,
      "learning_rate": 2.0142818647264888e-05,
      "loss": 3.2701,
      "step": 300
    },
    {
      "epoch": 0.05389382915656157,
      "grad_norm": 1.9082268476486206,
      "learning_rate": 2.6879547291835086e-05,
      "loss": 2.9703,
      "step": 400
    },
    {
      "epoch": 0.06736728644570197,
      "grad_norm": 1.4878844022750854,
      "learning_rate": 3.361627593640528e-05,
      "loss": 2.7243,
      "step": 500
    },
    {
      "epoch": 0.08084074373484236,
      "grad_norm": 1.728318452835083,
      "learning_rate": 4.035300458097548e-05,
      "loss": 2.4958,
      "step": 600
    },
    {
      "epoch": 0.09431420102398276,
      "grad_norm": 1.9488646984100342,
      "learning_rate": 4.708973322554568e-05,
      "loss": 2.3056,
      "step": 700
    },
    {
      "epoch": 0.10778765831312315,
      "grad_norm": 1.8756595849990845,
      "learning_rate": 5.382646187011587e-05,
      "loss": 2.1734,
      "step": 800
    },
    {
      "epoch": 0.12126111560226355,
      "grad_norm": 1.5761357545852661,
      "learning_rate": 6.056319051468607e-05,
      "loss": 2.0717,
      "step": 900
    },
    {
      "epoch": 0.13473457289140395,
      "grad_norm": 2.49153470993042,
      "learning_rate": 6.729991915925626e-05,
      "loss": 1.9891,
      "step": 1000
    },
    {
      "epoch": 0.14820803018054432,
      "grad_norm": 1.8852348327636719,
      "learning_rate": 7.403664780382646e-05,
      "loss": 1.9029,
      "step": 1100
    },
    {
      "epoch": 0.16168148746968472,
      "grad_norm": 1.363437533378601,
      "learning_rate": 8.077337644839666e-05,
      "loss": 1.8189,
      "step": 1200
    },
    {
      "epoch": 0.17515494475882512,
      "grad_norm": 1.6729093790054321,
      "learning_rate": 8.751010509296686e-05,
      "loss": 1.7352,
      "step": 1300
    },
    {
      "epoch": 0.18862840204796552,
      "grad_norm": 1.3850228786468506,
      "learning_rate": 9.424683373753705e-05,
      "loss": 1.6603,
      "step": 1400
    },
    {
      "epoch": 0.2021018593371059,
      "grad_norm": 1.0432305335998535,
      "learning_rate": 0.00010098356238210725,
      "loss": 1.5764,
      "step": 1500
    },
    {
      "epoch": 0.2155753166262463,
      "grad_norm": 1.245720386505127,
      "learning_rate": 0.00010772029102667745,
      "loss": 1.4896,
      "step": 1600
    },
    {
      "epoch": 0.2290487739153867,
      "grad_norm": 1.2359944581985474,
      "learning_rate": 0.00011445701967124765,
      "loss": 1.4112,
      "step": 1700
    },
    {
      "epoch": 0.2425222312045271,
      "grad_norm": 1.5725252628326416,
      "learning_rate": 0.00012119374831581784,
      "loss": 1.3437,
      "step": 1800
    },
    {
      "epoch": 0.2559956884936675,
      "grad_norm": 1.1958653926849365,
      "learning_rate": 0.00012793047696038804,
      "loss": 1.2826,
      "step": 1900
    },
    {
      "epoch": 0.2694691457828079,
      "grad_norm": 1.208345651626587,
      "learning_rate": 0.00013466720560495823,
      "loss": 1.2278,
      "step": 2000
    },
    {
      "epoch": 0.28294260307194824,
      "grad_norm": 0.9795716404914856,
      "learning_rate": 0.00014140393424952845,
      "loss": 1.182,
      "step": 2100
    },
    {
      "epoch": 0.29641606036108864,
      "grad_norm": 1.027790904045105,
      "learning_rate": 0.00014814066289409864,
      "loss": 1.1424,
      "step": 2200
    },
    {
      "epoch": 0.30988951765022904,
      "grad_norm": 1.060271143913269,
      "learning_rate": 0.00015487739153866882,
      "loss": 1.1004,
      "step": 2300
    },
    {
      "epoch": 0.32336297493936944,
      "grad_norm": 1.0012234449386597,
      "learning_rate": 0.000161614120183239,
      "loss": 1.0605,
      "step": 2400
    },
    {
      "epoch": 0.33683643222850984,
      "grad_norm": 0.9243299961090088,
      "learning_rate": 0.0001683508488278092,
      "loss": 1.0095,
      "step": 2500
    },
    {
      "epoch": 0.35030988951765024,
      "grad_norm": 1.3422080278396606,
      "learning_rate": 0.00017508757747237942,
      "loss": 0.9558,
      "step": 2600
    },
    {
      "epoch": 0.36378334680679064,
      "grad_norm": 1.0578101873397827,
      "learning_rate": 0.0001818243061169496,
      "loss": 0.9083,
      "step": 2700
    },
    {
      "epoch": 0.37725680409593104,
      "grad_norm": 0.9041587710380554,
      "learning_rate": 0.00018856103476151982,
      "loss": 0.8759,
      "step": 2800
    },
    {
      "epoch": 0.3907302613850714,
      "grad_norm": 0.9087947607040405,
      "learning_rate": 0.00019529776340609,
      "loss": 0.849,
      "step": 2900
    },
    {
      "epoch": 0.4042037186742118,
      "grad_norm": 0.9010210633277893,
      "learning_rate": 0.00020203449205066022,
      "loss": 0.8254,
      "step": 3000
    },
    {
      "epoch": 0.4176771759633522,
      "grad_norm": 0.884867787361145,
      "learning_rate": 0.0002087712206952304,
      "loss": 0.8045,
      "step": 3100
    },
    {
      "epoch": 0.4311506332524926,
      "grad_norm": 0.8793580532073975,
      "learning_rate": 0.00021550794933980057,
      "loss": 0.7866,
      "step": 3200
    },
    {
      "epoch": 0.444624090541633,
      "grad_norm": 0.8135902881622314,
      "learning_rate": 0.0002222446779843708,
      "loss": 0.7712,
      "step": 3300
    },
    {
      "epoch": 0.4580975478307734,
      "grad_norm": 0.8412314653396606,
      "learning_rate": 0.00022898140662894098,
      "loss": 0.7575,
      "step": 3400
    },
    {
      "epoch": 0.4715710051199138,
      "grad_norm": 0.8157561421394348,
      "learning_rate": 0.0002357181352735112,
      "loss": 0.7449,
      "step": 3500
    },
    {
      "epoch": 0.4850444624090542,
      "grad_norm": 0.89199298620224,
      "learning_rate": 0.00024245486391808138,
      "loss": 0.7327,
      "step": 3600
    },
    {
      "epoch": 0.49851791969819453,
      "grad_norm": 0.749671995639801,
      "learning_rate": 0.00024919159256265157,
      "loss": 0.7236,
      "step": 3700
    },
    {
      "epoch": 0.511991376987335,
      "grad_norm": 0.7049354910850525,
      "learning_rate": 0.0002559283212072218,
      "loss": 0.7121,
      "step": 3800
    },
    {
      "epoch": 0.5254648342764754,
      "grad_norm": 0.7413152456283569,
      "learning_rate": 0.00026266504985179194,
      "loss": 0.7038,
      "step": 3900
    },
    {
      "epoch": 0.5389382915656158,
      "grad_norm": 0.8080446720123291,
      "learning_rate": 0.00026940177849636216,
      "loss": 0.6954,
      "step": 4000
    },
    {
      "epoch": 0.5524117488547561,
      "grad_norm": 0.6535927057266235,
      "learning_rate": 0.0002761385071409324,
      "loss": 0.6898,
      "step": 4100
    },
    {
      "epoch": 0.5658852061438965,
      "grad_norm": 0.7123827934265137,
      "learning_rate": 0.00028287523578550254,
      "loss": 0.6817,
      "step": 4200
    },
    {
      "epoch": 0.5793586634330369,
      "grad_norm": 0.6640825867652893,
      "learning_rate": 0.00028961196443007275,
      "loss": 0.6754,
      "step": 4300
    },
    {
      "epoch": 0.5928321207221773,
      "grad_norm": 0.6870656609535217,
      "learning_rate": 0.00029634869307464297,
      "loss": 0.6689,
      "step": 4400
    },
    {
      "epoch": 0.6063055780113177,
      "grad_norm": 0.6682552695274353,
      "learning_rate": 0.0003030854217192132,
      "loss": 0.6632,
      "step": 4500
    },
    {
      "epoch": 0.6197790353004581,
      "grad_norm": 0.7342257499694824,
      "learning_rate": 0.00030982215036378334,
      "loss": 0.6574,
      "step": 4600
    },
    {
      "epoch": 0.6332524925895985,
      "grad_norm": 0.6166369915008545,
      "learning_rate": 0.00031655887900835356,
      "loss": 0.6527,
      "step": 4700
    },
    {
      "epoch": 0.6467259498787389,
      "grad_norm": 0.6189355850219727,
      "learning_rate": 0.0003232956076529238,
      "loss": 0.6462,
      "step": 4800
    },
    {
      "epoch": 0.6601994071678793,
      "grad_norm": 0.6251354813575745,
      "learning_rate": 0.00033003233629749394,
      "loss": 0.6426,
      "step": 4900
    },
    {
      "epoch": 0.6736728644570197,
      "grad_norm": 0.6698986887931824,
      "learning_rate": 0.00033676906494206415,
      "loss": 0.6382,
      "step": 5000
    },
    {
      "epoch": 0.6871463217461601,
      "grad_norm": 0.6165614128112793,
      "learning_rate": 0.00034350579358663437,
      "loss": 0.6325,
      "step": 5100
    },
    {
      "epoch": 0.7006197790353005,
      "grad_norm": 0.6032245755195618,
      "learning_rate": 0.00035024252223120453,
      "loss": 0.6289,
      "step": 5200
    },
    {
      "epoch": 0.7140932363244409,
      "grad_norm": 0.6178377866744995,
      "learning_rate": 0.0003569792508757747,
      "loss": 0.6263,
      "step": 5300
    },
    {
      "epoch": 0.7275666936135813,
      "grad_norm": 0.5898728966712952,
      "learning_rate": 0.0003637159795203449,
      "loss": 0.6212,
      "step": 5400
    },
    {
      "epoch": 0.7410401509027217,
      "grad_norm": 0.5766586065292358,
      "learning_rate": 0.0003704527081649151,
      "loss": 0.6195,
      "step": 5500
    },
    {
      "epoch": 0.7545136081918621,
      "grad_norm": 0.562961757183075,
      "learning_rate": 0.00037718943680948533,
      "loss": 0.6149,
      "step": 5600
    },
    {
      "epoch": 0.7679870654810024,
      "grad_norm": 0.5768886804580688,
      "learning_rate": 0.0003839261654540555,
      "loss": 0.6104,
      "step": 5700
    },
    {
      "epoch": 0.7814605227701428,
      "grad_norm": 0.5576419830322266,
      "learning_rate": 0.0003906628940986257,
      "loss": 0.6071,
      "step": 5800
    },
    {
      "epoch": 0.7949339800592832,
      "grad_norm": 0.5863984823226929,
      "learning_rate": 0.0003973996227431959,
      "loss": 0.6049,
      "step": 5900
    },
    {
      "epoch": 0.8084074373484236,
      "grad_norm": 0.5108187794685364,
      "learning_rate": 0.0004041363513877661,
      "loss": 0.6014,
      "step": 6000
    },
    {
      "epoch": 0.821880894637564,
      "grad_norm": 0.49313387274742126,
      "learning_rate": 0.0004108730800323363,
      "loss": 0.5973,
      "step": 6100
    },
    {
      "epoch": 0.8353543519267044,
      "grad_norm": 0.5230685472488403,
      "learning_rate": 0.0004176098086769065,
      "loss": 0.5952,
      "step": 6200
    },
    {
      "epoch": 0.8488278092158448,
      "grad_norm": 0.49161818623542786,
      "learning_rate": 0.00042434653732147673,
      "loss": 0.5926,
      "step": 6300
    },
    {
      "epoch": 0.8623012665049852,
      "grad_norm": 0.4863325357437134,
      "learning_rate": 0.0004310832659660469,
      "loss": 0.5886,
      "step": 6400
    },
    {
      "epoch": 0.8757747237941256,
      "grad_norm": 0.5223461985588074,
      "learning_rate": 0.0004378199946106171,
      "loss": 0.5862,
      "step": 6500
    },
    {
      "epoch": 0.889248181083266,
      "grad_norm": 0.4890427589416504,
      "learning_rate": 0.0004445567232551873,
      "loss": 0.583,
      "step": 6600
    },
    {
      "epoch": 0.9027216383724064,
      "grad_norm": 0.5191927552223206,
      "learning_rate": 0.0004512934518997575,
      "loss": 0.5818,
      "step": 6700
    },
    {
      "epoch": 0.9161950956615468,
      "grad_norm": 0.49901819229125977,
      "learning_rate": 0.00045803018054432765,
      "loss": 0.5778,
      "step": 6800
    },
    {
      "epoch": 0.9296685529506872,
      "grad_norm": 0.45645302534103394,
      "learning_rate": 0.00046476690918889786,
      "loss": 0.5763,
      "step": 6900
    },
    {
      "epoch": 0.9431420102398276,
      "grad_norm": 0.45765361189842224,
      "learning_rate": 0.0004715036378334681,
      "loss": 0.5734,
      "step": 7000
    },
    {
      "epoch": 0.956615467528968,
      "grad_norm": 0.4579680562019348,
      "learning_rate": 0.00047824036647803824,
      "loss": 0.571,
      "step": 7100
    },
    {
      "epoch": 0.9700889248181084,
      "grad_norm": 0.509912371635437,
      "learning_rate": 0.00048497709512260845,
      "loss": 0.5691,
      "step": 7200
    },
    {
      "epoch": 0.9835623821072487,
      "grad_norm": 0.4724940061569214,
      "learning_rate": 0.0004917138237671787,
      "loss": 0.5679,
      "step": 7300
    },
    {
      "epoch": 0.9970358393963891,
      "grad_norm": 0.43843597173690796,
      "learning_rate": 0.0004984505524117488,
      "loss": 0.5657,
      "step": 7400
    },
    {
      "epoch": 1.0,
      "eval_loss": 0.5205816626548767,
      "eval_runtime": 4.3256,
      "eval_samples_per_second": 1155.922,
      "eval_steps_per_second": 18.264,
      "step": 7422
    },
    {
      "epoch": 1.0105092966855296,
      "grad_norm": 0.43157443404197693,
      "learning_rate": 0.0004994236354381868,
      "loss": 0.5641,
      "step": 7500
    },
    {
      "epoch": 1.02398275397467,
      "grad_norm": 0.4503500461578369,
      "learning_rate": 0.0004986751100332346,
      "loss": 0.5611,
      "step": 7600
    },
    {
      "epoch": 1.0374562112638104,
      "grad_norm": 0.4287301003932953,
      "learning_rate": 0.0004979265846282823,
      "loss": 0.5596,
      "step": 7700
    },
    {
      "epoch": 1.0509296685529508,
      "grad_norm": 0.4516603350639343,
      "learning_rate": 0.00049717805922333,
      "loss": 0.556,
      "step": 7800
    },
    {
      "epoch": 1.0644031258420912,
      "grad_norm": 0.40748244524002075,
      "learning_rate": 0.0004964295338183778,
      "loss": 0.5551,
      "step": 7900
    },
    {
      "epoch": 1.0778765831312316,
      "grad_norm": 0.36990389227867126,
      "learning_rate": 0.0004956810084134255,
      "loss": 0.5541,
      "step": 8000
    },
    {
      "epoch": 1.0913500404203718,
      "grad_norm": 0.40630918741226196,
      "learning_rate": 0.0004949324830084733,
      "loss": 0.5507,
      "step": 8100
    },
    {
      "epoch": 1.1048234977095122,
      "grad_norm": 0.43332284688949585,
      "learning_rate": 0.000494183957603521,
      "loss": 0.5507,
      "step": 8200
    },
    {
      "epoch": 1.1182969549986526,
      "grad_norm": 0.4059982895851135,
      "learning_rate": 0.0004934354321985689,
      "loss": 0.5477,
      "step": 8300
    },
    {
      "epoch": 1.131770412287793,
      "grad_norm": 0.4003508985042572,
      "learning_rate": 0.0004926869067936166,
      "loss": 0.5459,
      "step": 8400
    },
    {
      "epoch": 1.1452438695769334,
      "grad_norm": 0.3854086101055145,
      "learning_rate": 0.0004919383813886644,
      "loss": 0.5446,
      "step": 8500
    },
    {
      "epoch": 1.1587173268660738,
      "grad_norm": 0.38457557559013367,
      "learning_rate": 0.000491189855983712,
      "loss": 0.5425,
      "step": 8600
    },
    {
      "epoch": 1.1721907841552142,
      "grad_norm": 0.38710325956344604,
      "learning_rate": 0.0004904413305787599,
      "loss": 0.5402,
      "step": 8700
    },
    {
      "epoch": 1.1856642414443546,
      "grad_norm": 0.4138777554035187,
      "learning_rate": 0.0004896928051738076,
      "loss": 0.5393,
      "step": 8800
    },
    {
      "epoch": 1.199137698733495,
      "grad_norm": 0.3746177554130554,
      "learning_rate": 0.0004889442797688554,
      "loss": 0.5366,
      "step": 8900
    },
    {
      "epoch": 1.2126111560226354,
      "grad_norm": 0.3979431390762329,
      "learning_rate": 0.00048819575436390313,
      "loss": 0.537,
      "step": 9000
    },
    {
      "epoch": 1.2260846133117758,
      "grad_norm": 0.3425014019012451,
      "learning_rate": 0.0004874472289589509,
      "loss": 0.5359,
      "step": 9100
    },
    {
      "epoch": 1.2395580706009162,
      "grad_norm": 0.34569936990737915,
      "learning_rate": 0.0004866987035539986,
      "loss": 0.5347,
      "step": 9200
    },
    {
      "epoch": 1.2530315278900566,
      "grad_norm": 0.3457697331905365,
      "learning_rate": 0.0004859501781490464,
      "loss": 0.5339,
      "step": 9300
    },
    {
      "epoch": 1.266504985179197,
      "grad_norm": 0.36079880595207214,
      "learning_rate": 0.0004852016527440942,
      "loss": 0.5324,
      "step": 9400
    },
    {
      "epoch": 1.2799784424683374,
      "grad_norm": 0.3214593529701233,
      "learning_rate": 0.00048445312733914187,
      "loss": 0.5316,
      "step": 9500
    },
    {
      "epoch": 1.2934518997574778,
      "grad_norm": 0.3538866639137268,
      "learning_rate": 0.0004837046019341896,
      "loss": 0.5288,
      "step": 9600
    },
    {
      "epoch": 1.3069253570466182,
      "grad_norm": 0.3519919216632843,
      "learning_rate": 0.0004829560765292374,
      "loss": 0.5284,
      "step": 9700
    },
    {
      "epoch": 1.3203988143357586,
      "grad_norm": 0.36186981201171875,
      "learning_rate": 0.00048220755112428516,
      "loss": 0.5257,
      "step": 9800
    },
    {
      "epoch": 1.333872271624899,
      "grad_norm": 0.372452974319458,
      "learning_rate": 0.0004814590257193329,
      "loss": 0.5271,
      "step": 9900
    },
    {
      "epoch": 1.3473457289140394,
      "grad_norm": 0.35614827275276184,
      "learning_rate": 0.00048071050031438066,
      "loss": 0.5266,
      "step": 10000
    },
    {
      "epoch": 1.3608191862031798,
      "grad_norm": 0.35077807307243347,
      "learning_rate": 0.00047996197490942846,
      "loss": 0.524,
      "step": 10100
    },
    {
      "epoch": 1.3742926434923202,
      "grad_norm": 0.3386443257331848,
      "learning_rate": 0.0004792134495044762,
      "loss": 0.5231,
      "step": 10200
    },
    {
      "epoch": 1.3877661007814606,
      "grad_norm": 0.33734357357025146,
      "learning_rate": 0.00047846492409952396,
      "loss": 0.5213,
      "step": 10300
    },
    {
      "epoch": 1.401239558070601,
      "grad_norm": 0.3467003107070923,
      "learning_rate": 0.0004777163986945717,
      "loss": 0.5211,
      "step": 10400
    },
    {
      "epoch": 1.4147130153597414,
      "grad_norm": 0.3384186625480652,
      "learning_rate": 0.00047696787328961945,
      "loss": 0.5204,
      "step": 10500
    },
    {
      "epoch": 1.4281864726488818,
      "grad_norm": 0.32893314957618713,
      "learning_rate": 0.0004762193478846672,
      "loss": 0.5196,
      "step": 10600
    },
    {
      "epoch": 1.4416599299380222,
      "grad_norm": 0.33770811557769775,
      "learning_rate": 0.00047547082247971495,
      "loss": 0.5169,
      "step": 10700
    },
    {
      "epoch": 1.4551333872271626,
      "grad_norm": 0.33103233575820923,
      "learning_rate": 0.0004747222970747627,
      "loss": 0.5183,
      "step": 10800
    },
    {
      "epoch": 1.468606844516303,
      "grad_norm": 0.3365427255630493,
      "learning_rate": 0.0004739737716698105,
      "loss": 0.5172,
      "step": 10900
    },
    {
      "epoch": 1.4820803018054431,
      "grad_norm": 0.2980721592903137,
      "learning_rate": 0.00047322524626485825,
      "loss": 0.5153,
      "step": 11000
    },
    {
      "epoch": 1.4955537590945838,
      "grad_norm": 0.3267720937728882,
      "learning_rate": 0.000472476720859906,
      "loss": 0.5152,
      "step": 11100
    },
    {
      "epoch": 1.509027216383724,
      "grad_norm": 0.298345148563385,
      "learning_rate": 0.00047172819545495374,
      "loss": 0.5143,
      "step": 11200
    },
    {
      "epoch": 1.5225006736728646,
      "grad_norm": 0.3176594376564026,
      "learning_rate": 0.00047097967005000155,
      "loss": 0.513,
      "step": 11300
    },
    {
      "epoch": 1.5359741309620047,
      "grad_norm": 0.33607107400894165,
      "learning_rate": 0.00047023114464504924,
      "loss": 0.5124,
      "step": 11400
    },
    {
      "epoch": 1.5494475882511454,
      "grad_norm": 0.34215059876441956,
      "learning_rate": 0.000469482619240097,
      "loss": 0.511,
      "step": 11500
    },
    {
      "epoch": 1.5629210455402855,
      "grad_norm": 0.32337313890457153,
      "learning_rate": 0.00046873409383514473,
      "loss": 0.5111,
      "step": 11600
    },
    {
      "epoch": 1.5763945028294262,
      "grad_norm": 0.3245720863342285,
      "learning_rate": 0.00046798556843019254,
      "loss": 0.5104,
      "step": 11700
    },
    {
      "epoch": 1.5898679601185663,
      "grad_norm": 0.30848073959350586,
      "learning_rate": 0.0004672370430252403,
      "loss": 0.5093,
      "step": 11800
    },
    {
      "epoch": 1.603341417407707,
      "grad_norm": 0.3107387125492096,
      "learning_rate": 0.00046648851762028803,
      "loss": 0.5084,
      "step": 11900
    },
    {
      "epoch": 1.6168148746968471,
      "grad_norm": 0.2882945239543915,
      "learning_rate": 0.0004657399922153358,
      "loss": 0.5086,
      "step": 12000
    },
    {
      "epoch": 1.6302883319859878,
      "grad_norm": 0.2892763912677765,
      "learning_rate": 0.0004649914668103836,
      "loss": 0.5063,
      "step": 12100
    },
    {
      "epoch": 1.643761789275128,
      "grad_norm": 0.3142216205596924,
      "learning_rate": 0.00046424294140543133,
      "loss": 0.5064,
      "step": 12200
    },
    {
      "epoch": 1.6572352465642683,
      "grad_norm": 0.29723140597343445,
      "learning_rate": 0.0004634944160004791,
      "loss": 0.5062,
      "step": 12300
    },
    {
      "epoch": 1.6707087038534087,
      "grad_norm": 0.30053964257240295,
      "learning_rate": 0.00046274589059552677,
      "loss": 0.5052,
      "step": 12400
    },
    {
      "epoch": 1.6841821611425492,
      "grad_norm": 0.3240768313407898,
      "learning_rate": 0.0004619973651905746,
      "loss": 0.5038,
      "step": 12500
    },
    {
      "epoch": 1.6976556184316896,
      "grad_norm": 0.3062553107738495,
      "learning_rate": 0.0004612488397856223,
      "loss": 0.5049,
      "step": 12600
    },
    {
      "epoch": 1.71112907572083,
      "grad_norm": 0.2978423833847046,
      "learning_rate": 0.00046050031438067007,
      "loss": 0.5034,
      "step": 12700
    },
    {
      "epoch": 1.7246025330099704,
      "grad_norm": 0.29889827966690063,
      "learning_rate": 0.00045975178897571787,
      "loss": 0.5037,
      "step": 12800
    },
    {
      "epoch": 1.7380759902991108,
      "grad_norm": 0.29492929577827454,
      "learning_rate": 0.0004590032635707656,
      "loss": 0.5021,
      "step": 12900
    },
    {
      "epoch": 1.7515494475882512,
      "grad_norm": 0.28087761998176575,
      "learning_rate": 0.00045825473816581337,
      "loss": 0.4999,
      "step": 13000
    },
    {
      "epoch": 1.7650229048773916,
      "grad_norm": 0.2926037609577179,
      "learning_rate": 0.0004575062127608611,
      "loss": 0.501,
      "step": 13100
    },
    {
      "epoch": 1.778496362166532,
      "grad_norm": 0.29843050241470337,
      "learning_rate": 0.0004567576873559089,
      "loss": 0.5008,
      "step": 13200
    },
    {
      "epoch": 1.7919698194556724,
      "grad_norm": 0.27232763171195984,
      "learning_rate": 0.00045600916195095666,
      "loss": 0.4991,
      "step": 13300
    },
    {
      "epoch": 1.8054432767448128,
      "grad_norm": 0.295836478471756,
      "learning_rate": 0.00045526063654600436,
      "loss": 0.5012,
      "step": 13400
    },
    {
      "epoch": 1.8189167340339532,
      "grad_norm": 0.2825106978416443,
      "learning_rate": 0.0004545121111410521,
      "loss": 0.5004,
      "step": 13500
    },
    {
      "epoch": 1.8323901913230936,
      "grad_norm": 0.275799036026001,
      "learning_rate": 0.0004537635857360999,
      "loss": 0.4981,
      "step": 13600
    },
    {
      "epoch": 1.845863648612234,
      "grad_norm": 0.2883085012435913,
      "learning_rate": 0.00045301506033114766,
      "loss": 0.4978,
      "step": 13700
    },
    {
      "epoch": 1.8593371059013744,
      "grad_norm": 0.2868999242782593,
      "learning_rate": 0.0004522665349261954,
      "loss": 0.4974,
      "step": 13800
    },
    {
      "epoch": 1.8728105631905145,
      "grad_norm": 0.27770593762397766,
      "learning_rate": 0.00045151800952124315,
      "loss": 0.4975,
      "step": 13900
    },
    {
      "epoch": 1.8862840204796552,
      "grad_norm": 0.29534652829170227,
      "learning_rate": 0.00045076948411629095,
      "loss": 0.4969,
      "step": 14000
    },
    {
      "epoch": 1.8997574777687953,
      "grad_norm": 0.2921862304210663,
      "learning_rate": 0.0004500209587113387,
      "loss": 0.496,
      "step": 14100
    },
    {
      "epoch": 1.913230935057936,
      "grad_norm": 0.2782873511314392,
      "learning_rate": 0.00044927243330638645,
      "loss": 0.4977,
      "step": 14200
    },
    {
      "epoch": 1.9267043923470761,
      "grad_norm": 0.28368449211120605,
      "learning_rate": 0.00044852390790143414,
      "loss": 0.4958,
      "step": 14300
    },
    {
      "epoch": 1.9401778496362168,
      "grad_norm": 0.28548285365104675,
      "learning_rate": 0.00044777538249648194,
      "loss": 0.4954,
      "step": 14400
    },
    {
      "epoch": 1.953651306925357,
      "grad_norm": 0.291544646024704,
      "learning_rate": 0.0004470268570915297,
      "loss": 0.4953,
      "step": 14500
    },
    {
      "epoch": 1.9671247642144976,
      "grad_norm": 0.2689151167869568,
      "learning_rate": 0.00044627833168657744,
      "loss": 0.4937,
      "step": 14600
    },
    {
      "epoch": 1.9805982215036377,
      "grad_norm": 0.2887156307697296,
      "learning_rate": 0.0004455298062816252,
      "loss": 0.4933,
      "step": 14700
    },
    {
      "epoch": 1.9940716787927784,
      "grad_norm": 0.28881117701530457,
      "learning_rate": 0.000444781280876673,
      "loss": 0.4929,
      "step": 14800
    },
    {
      "epoch": 2.0,
      "eval_loss": 0.45925790071487427,
      "eval_runtime": 4.3243,
      "eval_samples_per_second": 1156.247,
      "eval_steps_per_second": 18.269,
      "step": 14844
    }
  ],
  "logging_steps": 100,
  "max_steps": 74220,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 2723544268800000.0,
  "train_batch_size": 128,
  "trial_name": null,
  "trial_params": null
}
