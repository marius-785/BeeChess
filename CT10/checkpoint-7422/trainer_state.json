{
  "best_global_step": 7422,
  "best_metric": 0.4905397891998291,
  "best_model_checkpoint": "./CT10/checkpoint-7422",
  "epoch": 2.0,
  "eval_steps": 500,
  "global_step": 7422,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.026946914578280787,
      "grad_norm": 2.1383094787597656,
      "learning_rate": 1.333872271624899e-05,
      "loss": 4.1878,
      "step": 100
    },
    {
      "epoch": 0.05389382915656157,
      "grad_norm": 2.3672401905059814,
      "learning_rate": 2.6812180005389382e-05,
      "loss": 3.5737,
      "step": 200
    },
    {
      "epoch": 0.08084074373484236,
      "grad_norm": 2.042370557785034,
      "learning_rate": 4.0285637294529775e-05,
      "loss": 3.1121,
      "step": 300
    },
    {
      "epoch": 0.10778765831312315,
      "grad_norm": 1.5097312927246094,
      "learning_rate": 5.375909458367017e-05,
      "loss": 2.7672,
      "step": 400
    },
    {
      "epoch": 0.13473457289140395,
      "grad_norm": 1.7142856121063232,
      "learning_rate": 6.723255187281056e-05,
      "loss": 2.4414,
      "step": 500
    },
    {
      "epoch": 0.16168148746968472,
      "grad_norm": 2.254181146621704,
      "learning_rate": 8.070600916195097e-05,
      "loss": 2.224,
      "step": 600
    },
    {
      "epoch": 0.18862840204796552,
      "grad_norm": 1.2850652933120728,
      "learning_rate": 9.417946645109136e-05,
      "loss": 2.058,
      "step": 700
    },
    {
      "epoch": 0.2155753166262463,
      "grad_norm": 1.8770676851272583,
      "learning_rate": 0.00010765292374023175,
      "loss": 1.928,
      "step": 800
    },
    {
      "epoch": 0.2425222312045271,
      "grad_norm": 1.1676158905029297,
      "learning_rate": 0.00012112638102937214,
      "loss": 1.7943,
      "step": 900
    },
    {
      "epoch": 0.2694691457828079,
      "grad_norm": 1.0422593355178833,
      "learning_rate": 0.0001345998383185125,
      "loss": 1.646,
      "step": 1000
    },
    {
      "epoch": 0.29641606036108864,
      "grad_norm": 1.1601406335830688,
      "learning_rate": 0.00014807329560765292,
      "loss": 1.5014,
      "step": 1100
    },
    {
      "epoch": 0.32336297493936944,
      "grad_norm": 1.2168995141983032,
      "learning_rate": 0.00016154675289679332,
      "loss": 1.381,
      "step": 1200
    },
    {
      "epoch": 0.35030988951765024,
      "grad_norm": 1.2300795316696167,
      "learning_rate": 0.00017502021018593372,
      "loss": 1.279,
      "step": 1300
    },
    {
      "epoch": 0.37725680409593104,
      "grad_norm": 1.6626192331314087,
      "learning_rate": 0.0001884936674750741,
      "loss": 1.1593,
      "step": 1400
    },
    {
      "epoch": 0.4042037186742118,
      "grad_norm": 1.4006414413452148,
      "learning_rate": 0.0002019671247642145,
      "loss": 1.067,
      "step": 1500
    },
    {
      "epoch": 0.4311506332524926,
      "grad_norm": 0.9579497575759888,
      "learning_rate": 0.0002154405820533549,
      "loss": 0.9951,
      "step": 1600
    },
    {
      "epoch": 0.4580975478307734,
      "grad_norm": 1.1298301219940186,
      "learning_rate": 0.0002289140393424953,
      "loss": 0.944,
      "step": 1700
    },
    {
      "epoch": 0.4850444624090542,
      "grad_norm": 1.2277151346206665,
      "learning_rate": 0.00024238749663163569,
      "loss": 0.9013,
      "step": 1800
    },
    {
      "epoch": 0.511991376987335,
      "grad_norm": 0.860411524772644,
      "learning_rate": 0.0002558609539207761,
      "loss": 0.8623,
      "step": 1900
    },
    {
      "epoch": 0.5389382915656158,
      "grad_norm": 0.8773190975189209,
      "learning_rate": 0.00026933441120991647,
      "loss": 0.8272,
      "step": 2000
    },
    {
      "epoch": 0.5658852061438965,
      "grad_norm": 0.7234193086624146,
      "learning_rate": 0.0002828078684990569,
      "loss": 0.7986,
      "step": 2100
    },
    {
      "epoch": 0.5928321207221773,
      "grad_norm": 0.7599690556526184,
      "learning_rate": 0.0002962813257881973,
      "loss": 0.7742,
      "step": 2200
    },
    {
      "epoch": 0.6197790353004581,
      "grad_norm": 0.8441469073295593,
      "learning_rate": 0.00030975478307733765,
      "loss": 0.7554,
      "step": 2300
    },
    {
      "epoch": 0.6467259498787389,
      "grad_norm": 0.732752799987793,
      "learning_rate": 0.000323228240366478,
      "loss": 0.7381,
      "step": 2400
    },
    {
      "epoch": 0.6736728644570197,
      "grad_norm": 0.6894033551216125,
      "learning_rate": 0.0003367016976556184,
      "loss": 0.7253,
      "step": 2500
    },
    {
      "epoch": 0.7006197790353005,
      "grad_norm": 0.8421542048454285,
      "learning_rate": 0.00035017515494475883,
      "loss": 0.7115,
      "step": 2600
    },
    {
      "epoch": 0.7275666936135813,
      "grad_norm": 0.8428652882575989,
      "learning_rate": 0.0003636486122338992,
      "loss": 0.7015,
      "step": 2700
    },
    {
      "epoch": 0.7545136081918621,
      "grad_norm": 0.6947404742240906,
      "learning_rate": 0.00037712206952303964,
      "loss": 0.6904,
      "step": 2800
    },
    {
      "epoch": 0.7814605227701428,
      "grad_norm": 0.661942183971405,
      "learning_rate": 0.00039059552681218,
      "loss": 0.6785,
      "step": 2900
    },
    {
      "epoch": 0.8084074373484236,
      "grad_norm": 0.6512113213539124,
      "learning_rate": 0.00040406898410132045,
      "loss": 0.6699,
      "step": 3000
    },
    {
      "epoch": 0.8353543519267044,
      "grad_norm": 0.5276344418525696,
      "learning_rate": 0.0004175424413904608,
      "loss": 0.6599,
      "step": 3100
    },
    {
      "epoch": 0.8623012665049852,
      "grad_norm": 0.753773033618927,
      "learning_rate": 0.00043101589867960115,
      "loss": 0.6532,
      "step": 3200
    },
    {
      "epoch": 0.889248181083266,
      "grad_norm": 0.6003670692443848,
      "learning_rate": 0.0004444893559687416,
      "loss": 0.646,
      "step": 3300
    },
    {
      "epoch": 0.9161950956615468,
      "grad_norm": 0.6350364089012146,
      "learning_rate": 0.00045796281325788195,
      "loss": 0.6388,
      "step": 3400
    },
    {
      "epoch": 0.9431420102398276,
      "grad_norm": 0.5920190215110779,
      "learning_rate": 0.0004714362705470224,
      "loss": 0.6334,
      "step": 3500
    },
    {
      "epoch": 0.9700889248181084,
      "grad_norm": 0.5770727396011353,
      "learning_rate": 0.00048490972783616276,
      "loss": 0.6279,
      "step": 3600
    },
    {
      "epoch": 0.9970358393963891,
      "grad_norm": 0.5906470417976379,
      "learning_rate": 0.0004983831851253031,
      "loss": 0.6237,
      "step": 3700
    },
    {
      "epoch": 1.0,
      "eval_loss": 0.5692958235740662,
      "eval_runtime": 4.2816,
      "eval_samples_per_second": 1167.776,
      "eval_steps_per_second": 18.451,
      "step": 3711
    },
    {
      "epoch": 1.02398275397467,
      "grad_norm": 0.541117787361145,
      "learning_rate": 0.0004986825952872841,
      "loss": 0.6184,
      "step": 3800
    },
    {
      "epoch": 1.0509296685529508,
      "grad_norm": 0.5130571126937866,
      "learning_rate": 0.0004971855444773796,
      "loss": 0.6116,
      "step": 3900
    },
    {
      "epoch": 1.0778765831312316,
      "grad_norm": 0.5071808695793152,
      "learning_rate": 0.000495688493667475,
      "loss": 0.6077,
      "step": 4000
    },
    {
      "epoch": 1.1048234977095122,
      "grad_norm": 0.5216901898384094,
      "learning_rate": 0.0004941914428575707,
      "loss": 0.6038,
      "step": 4100
    },
    {
      "epoch": 1.131770412287793,
      "grad_norm": 0.4478909969329834,
      "learning_rate": 0.000492694392047666,
      "loss": 0.5993,
      "step": 4200
    },
    {
      "epoch": 1.1587173268660738,
      "grad_norm": 0.49206095933914185,
      "learning_rate": 0.0004911973412377616,
      "loss": 0.5954,
      "step": 4300
    },
    {
      "epoch": 1.1856642414443546,
      "grad_norm": 0.47023478150367737,
      "learning_rate": 0.0004897002904278571,
      "loss": 0.5915,
      "step": 4400
    },
    {
      "epoch": 1.2126111560226354,
      "grad_norm": 0.49130740761756897,
      "learning_rate": 0.00048820323961795264,
      "loss": 0.588,
      "step": 4500
    },
    {
      "epoch": 1.2395580706009162,
      "grad_norm": 0.439310759305954,
      "learning_rate": 0.0004867061888080482,
      "loss": 0.5855,
      "step": 4600
    },
    {
      "epoch": 1.266504985179197,
      "grad_norm": 0.48713210225105286,
      "learning_rate": 0.00048520913799814363,
      "loss": 0.5818,
      "step": 4700
    },
    {
      "epoch": 1.2934518997574778,
      "grad_norm": 0.5056836009025574,
      "learning_rate": 0.0004837120871882392,
      "loss": 0.5797,
      "step": 4800
    },
    {
      "epoch": 1.3203988143357586,
      "grad_norm": 0.4256507456302643,
      "learning_rate": 0.0004822150363783347,
      "loss": 0.5755,
      "step": 4900
    },
    {
      "epoch": 1.3473457289140394,
      "grad_norm": 0.47428739070892334,
      "learning_rate": 0.0004807179855684302,
      "loss": 0.5744,
      "step": 5000
    },
    {
      "epoch": 1.3742926434923202,
      "grad_norm": 0.4279983937740326,
      "learning_rate": 0.0004792209347585257,
      "loss": 0.5771,
      "step": 5100
    },
    {
      "epoch": 1.401239558070601,
      "grad_norm": 0.4213838279247284,
      "learning_rate": 0.0004777238839486212,
      "loss": 0.5682,
      "step": 5200
    },
    {
      "epoch": 1.4281864726488818,
      "grad_norm": 0.3742353320121765,
      "learning_rate": 0.0004762268331387167,
      "loss": 0.5662,
      "step": 5300
    },
    {
      "epoch": 1.4551333872271626,
      "grad_norm": 0.3827490508556366,
      "learning_rate": 0.00047472978232881226,
      "loss": 0.563,
      "step": 5400
    },
    {
      "epoch": 1.4820803018054431,
      "grad_norm": 0.4039304554462433,
      "learning_rate": 0.00047323273151890776,
      "loss": 0.5612,
      "step": 5500
    },
    {
      "epoch": 1.509027216383724,
      "grad_norm": 0.3773376941680908,
      "learning_rate": 0.0004717356807090033,
      "loss": 0.5596,
      "step": 5600
    },
    {
      "epoch": 1.5359741309620047,
      "grad_norm": 0.36746761202812195,
      "learning_rate": 0.00047023862989909875,
      "loss": 0.5562,
      "step": 5700
    },
    {
      "epoch": 1.5629210455402855,
      "grad_norm": 0.3883555233478546,
      "learning_rate": 0.0004687415790891943,
      "loss": 0.5546,
      "step": 5800
    },
    {
      "epoch": 1.5898679601185663,
      "grad_norm": 0.38910648226737976,
      "learning_rate": 0.0004672445282792898,
      "loss": 0.5526,
      "step": 5900
    },
    {
      "epoch": 1.6168148746968471,
      "grad_norm": 0.43312814831733704,
      "learning_rate": 0.00046574747746938534,
      "loss": 0.5509,
      "step": 6000
    },
    {
      "epoch": 1.643761789275128,
      "grad_norm": 0.3625759780406952,
      "learning_rate": 0.0004642504266594808,
      "loss": 0.5482,
      "step": 6100
    },
    {
      "epoch": 1.6707087038534087,
      "grad_norm": 0.3424108922481537,
      "learning_rate": 0.00046275337584957633,
      "loss": 0.5468,
      "step": 6200
    },
    {
      "epoch": 1.6976556184316896,
      "grad_norm": 0.36350056529045105,
      "learning_rate": 0.00046125632503967183,
      "loss": 0.5448,
      "step": 6300
    },
    {
      "epoch": 1.7246025330099704,
      "grad_norm": 0.35404083132743835,
      "learning_rate": 0.0004597592742297674,
      "loss": 0.5433,
      "step": 6400
    },
    {
      "epoch": 1.7515494475882512,
      "grad_norm": 0.35263609886169434,
      "learning_rate": 0.0004582622234198629,
      "loss": 0.5401,
      "step": 6500
    },
    {
      "epoch": 1.778496362166532,
      "grad_norm": 0.3216622471809387,
      "learning_rate": 0.00045676517260995837,
      "loss": 0.5401,
      "step": 6600
    },
    {
      "epoch": 1.8054432767448128,
      "grad_norm": 0.3450595736503601,
      "learning_rate": 0.00045526812180005387,
      "loss": 0.5382,
      "step": 6700
    },
    {
      "epoch": 1.8323901913230936,
      "grad_norm": 0.33271896839141846,
      "learning_rate": 0.0004537710709901494,
      "loss": 0.5363,
      "step": 6800
    },
    {
      "epoch": 1.8593371059013744,
      "grad_norm": 0.4127448797225952,
      "learning_rate": 0.0004522740201802449,
      "loss": 0.5351,
      "step": 6900
    },
    {
      "epoch": 1.8862840204796552,
      "grad_norm": 0.341653972864151,
      "learning_rate": 0.00045077696937034046,
      "loss": 0.534,
      "step": 7000
    },
    {
      "epoch": 1.913230935057936,
      "grad_norm": 0.32377851009368896,
      "learning_rate": 0.0004492799185604359,
      "loss": 0.5327,
      "step": 7100
    },
    {
      "epoch": 1.9401778496362168,
      "grad_norm": 0.3440527021884918,
      "learning_rate": 0.00044778286775053145,
      "loss": 0.5309,
      "step": 7200
    },
    {
      "epoch": 1.9671247642144976,
      "grad_norm": 0.35889342427253723,
      "learning_rate": 0.00044628581694062695,
      "loss": 0.5293,
      "step": 7300
    },
    {
      "epoch": 1.9940716787927784,
      "grad_norm": 0.3863030970096588,
      "learning_rate": 0.0004447887661307225,
      "loss": 0.5278,
      "step": 7400
    },
    {
      "epoch": 2.0,
      "eval_loss": 0.4905397891998291,
      "eval_runtime": 4.2415,
      "eval_samples_per_second": 1178.841,
      "eval_steps_per_second": 18.626,
      "step": 7422
    }
  ],
  "logging_steps": 100,
  "max_steps": 37110,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 2719178342400000.0,
  "train_batch_size": 256,
  "trial_name": null,
  "trial_params": null
}
