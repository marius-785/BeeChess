{
  "best_global_step": 3711,
  "best_metric": 0.5445102453231812,
  "best_model_checkpoint": "./O6/checkpoint-3711",
  "epoch": 1.0,
  "eval_steps": 500,
  "global_step": 3711,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.026946914578280787,
      "grad_norm": 2.031421184539795,
      "learning_rate": 0.00013306451612903227,
      "loss": 3.6777,
      "step": 100
    },
    {
      "epoch": 0.05389382915656157,
      "grad_norm": 0.8619571328163147,
      "learning_rate": 0.0002674731182795699,
      "loss": 2.4849,
      "step": 200
    },
    {
      "epoch": 0.08084074373484236,
      "grad_norm": 1.993701457977295,
      "learning_rate": 0.00040188172043010753,
      "loss": 1.9941,
      "step": 300
    },
    {
      "epoch": 0.10778765831312315,
      "grad_norm": 0.8188154697418213,
      "learning_rate": 0.0004959568733153639,
      "loss": 1.7204,
      "step": 400
    },
    {
      "epoch": 0.13473457289140395,
      "grad_norm": 0.885909378528595,
      "learning_rate": 0.0004809823300389338,
      "loss": 1.4344,
      "step": 500
    },
    {
      "epoch": 0.16168148746968472,
      "grad_norm": 0.7229626178741455,
      "learning_rate": 0.0004660077867625038,
      "loss": 1.2235,
      "step": 600
    },
    {
      "epoch": 0.18862840204796552,
      "grad_norm": 0.774725615978241,
      "learning_rate": 0.0004510332434860737,
      "loss": 1.0347,
      "step": 700
    },
    {
      "epoch": 0.2155753166262463,
      "grad_norm": 0.7204486131668091,
      "learning_rate": 0.0004360587002096436,
      "loss": 0.912,
      "step": 800
    },
    {
      "epoch": 0.2425222312045271,
      "grad_norm": 0.6367270946502686,
      "learning_rate": 0.00042108415693321356,
      "loss": 0.8461,
      "step": 900
    },
    {
      "epoch": 0.2694691457828079,
      "grad_norm": 0.6075888872146606,
      "learning_rate": 0.00040610961365678347,
      "loss": 0.8025,
      "step": 1000
    },
    {
      "epoch": 0.29641606036108864,
      "grad_norm": 0.538646936416626,
      "learning_rate": 0.0003911350703803534,
      "loss": 0.7698,
      "step": 1100
    },
    {
      "epoch": 0.32336297493936944,
      "grad_norm": 0.5523360371589661,
      "learning_rate": 0.00037616052710392334,
      "loss": 0.7438,
      "step": 1200
    },
    {
      "epoch": 0.35030988951765024,
      "grad_norm": 0.4953463673591614,
      "learning_rate": 0.0003611859838274933,
      "loss": 0.7239,
      "step": 1300
    },
    {
      "epoch": 0.37725680409593104,
      "grad_norm": 0.5402494668960571,
      "learning_rate": 0.0003462114405510632,
      "loss": 0.7067,
      "step": 1400
    },
    {
      "epoch": 0.4042037186742118,
      "grad_norm": 0.5340362191200256,
      "learning_rate": 0.0003312368972746331,
      "loss": 0.6951,
      "step": 1500
    },
    {
      "epoch": 0.4311506332524926,
      "grad_norm": 0.507578432559967,
      "learning_rate": 0.0003162623539982031,
      "loss": 0.6821,
      "step": 1600
    },
    {
      "epoch": 0.4580975478307734,
      "grad_norm": 0.49809524416923523,
      "learning_rate": 0.000301287810721773,
      "loss": 0.6719,
      "step": 1700
    },
    {
      "epoch": 0.4850444624090542,
      "grad_norm": 0.4765617847442627,
      "learning_rate": 0.0002863132674453429,
      "loss": 0.6636,
      "step": 1800
    },
    {
      "epoch": 0.511991376987335,
      "grad_norm": 0.47134700417518616,
      "learning_rate": 0.00027133872416891286,
      "loss": 0.6556,
      "step": 1900
    },
    {
      "epoch": 0.5389382915656158,
      "grad_norm": 0.4604669511318207,
      "learning_rate": 0.0002563641808924828,
      "loss": 0.6472,
      "step": 2000
    },
    {
      "epoch": 0.5658852061438965,
      "grad_norm": 0.452540785074234,
      "learning_rate": 0.0002413896376160527,
      "loss": 0.6415,
      "step": 2100
    },
    {
      "epoch": 0.5928321207221773,
      "grad_norm": 0.48351141810417175,
      "learning_rate": 0.00022641509433962264,
      "loss": 0.6351,
      "step": 2200
    },
    {
      "epoch": 0.6197790353004581,
      "grad_norm": 0.4501040577888489,
      "learning_rate": 0.00021144055106319258,
      "loss": 0.6302,
      "step": 2300
    },
    {
      "epoch": 0.6467259498787389,
      "grad_norm": 0.4393273890018463,
      "learning_rate": 0.0001964660077867625,
      "loss": 0.6242,
      "step": 2400
    },
    {
      "epoch": 0.6736728644570197,
      "grad_norm": 0.41267335414886475,
      "learning_rate": 0.00018149146451033245,
      "loss": 0.6206,
      "step": 2500
    },
    {
      "epoch": 0.7006197790353005,
      "grad_norm": 0.42024731636047363,
      "learning_rate": 0.00016651692123390236,
      "loss": 0.6153,
      "step": 2600
    },
    {
      "epoch": 0.7275666936135813,
      "grad_norm": 0.41220822930336,
      "learning_rate": 0.0001515423779574723,
      "loss": 0.6128,
      "step": 2700
    },
    {
      "epoch": 0.7545136081918621,
      "grad_norm": 0.41225236654281616,
      "learning_rate": 0.00013656783468104223,
      "loss": 0.6099,
      "step": 2800
    },
    {
      "epoch": 0.7814605227701428,
      "grad_norm": 0.42782720923423767,
      "learning_rate": 0.00012159329140461216,
      "loss": 0.6059,
      "step": 2900
    },
    {
      "epoch": 0.8084074373484236,
      "grad_norm": 0.40252089500427246,
      "learning_rate": 0.00010661874812818209,
      "loss": 0.6045,
      "step": 3000
    },
    {
      "epoch": 0.8353543519267044,
      "grad_norm": 0.37917226552963257,
      "learning_rate": 9.164420485175202e-05,
      "loss": 0.6008,
      "step": 3100
    },
    {
      "epoch": 0.8623012665049852,
      "grad_norm": 0.3957862854003906,
      "learning_rate": 7.666966157532196e-05,
      "loss": 0.5987,
      "step": 3200
    },
    {
      "epoch": 0.889248181083266,
      "grad_norm": 0.412855863571167,
      "learning_rate": 6.169511829889188e-05,
      "loss": 0.5968,
      "step": 3300
    },
    {
      "epoch": 0.9161950956615468,
      "grad_norm": 0.3696760833263397,
      "learning_rate": 4.6720575022461816e-05,
      "loss": 0.5947,
      "step": 3400
    },
    {
      "epoch": 0.9431420102398276,
      "grad_norm": 0.34276217222213745,
      "learning_rate": 3.1746031746031745e-05,
      "loss": 0.5934,
      "step": 3500
    },
    {
      "epoch": 0.9700889248181084,
      "grad_norm": 0.35614001750946045,
      "learning_rate": 1.6771488469601677e-05,
      "loss": 0.5922,
      "step": 3600
    },
    {
      "epoch": 0.9970358393963891,
      "grad_norm": 0.3132787346839905,
      "learning_rate": 1.7969451931716085e-06,
      "loss": 0.5925,
      "step": 3700
    },
    {
      "epoch": 1.0,
      "eval_loss": 0.5445102453231812,
      "eval_runtime": 4.3056,
      "eval_samples_per_second": 1161.274,
      "eval_steps_per_second": 18.348,
      "step": 3711
    }
  ],
  "logging_steps": 100,
  "max_steps": 3711,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 1359589171200000.0,
  "train_batch_size": 256,
  "trial_name": null,
  "trial_params": null
}
