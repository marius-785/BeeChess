{
  "best_global_step": 3711,
  "best_metric": 0.567869246006012,
  "best_model_checkpoint": "./CPTkzer/checkpoint-3711",
  "epoch": 1.0,
  "eval_steps": 500,
  "global_step": 3711,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.026946914578280787,
      "grad_norm": 2.0099430084228516,
      "learning_rate": 0.00013306451612903227,
      "loss": 3.6833,
      "step": 100
    },
    {
      "epoch": 0.05389382915656157,
      "grad_norm": 2.8965961933135986,
      "learning_rate": 0.0002674731182795699,
      "loss": 2.462,
      "step": 200
    },
    {
      "epoch": 0.08084074373484236,
      "grad_norm": 0.9199718832969666,
      "learning_rate": 0.00040188172043010753,
      "loss": 2.011,
      "step": 300
    },
    {
      "epoch": 0.10778765831312315,
      "grad_norm": 0.5970994234085083,
      "learning_rate": 0.0004959568733153639,
      "loss": 1.7143,
      "step": 400
    },
    {
      "epoch": 0.13473457289140395,
      "grad_norm": 0.6743489503860474,
      "learning_rate": 0.0004809823300389338,
      "loss": 1.3735,
      "step": 500
    },
    {
      "epoch": 0.16168148746968472,
      "grad_norm": 0.882832407951355,
      "learning_rate": 0.0004660077867625038,
      "loss": 1.164,
      "step": 600
    },
    {
      "epoch": 0.18862840204796552,
      "grad_norm": 0.6738079786300659,
      "learning_rate": 0.0004510332434860737,
      "loss": 1.0184,
      "step": 700
    },
    {
      "epoch": 0.2155753166262463,
      "grad_norm": 0.6977720856666565,
      "learning_rate": 0.0004360587002096436,
      "loss": 0.9298,
      "step": 800
    },
    {
      "epoch": 0.2425222312045271,
      "grad_norm": 0.6250754594802856,
      "learning_rate": 0.00042108415693321356,
      "loss": 0.8743,
      "step": 900
    },
    {
      "epoch": 0.2694691457828079,
      "grad_norm": 0.7116755843162537,
      "learning_rate": 0.00040610961365678347,
      "loss": 0.8341,
      "step": 1000
    },
    {
      "epoch": 0.29641606036108864,
      "grad_norm": 0.7149754166603088,
      "learning_rate": 0.0003911350703803534,
      "loss": 0.8057,
      "step": 1100
    },
    {
      "epoch": 0.32336297493936944,
      "grad_norm": 0.5784909129142761,
      "learning_rate": 0.00037616052710392334,
      "loss": 0.781,
      "step": 1200
    },
    {
      "epoch": 0.35030988951765024,
      "grad_norm": 0.6591125726699829,
      "learning_rate": 0.0003611859838274933,
      "loss": 0.762,
      "step": 1300
    },
    {
      "epoch": 0.37725680409593104,
      "grad_norm": 0.5912294387817383,
      "learning_rate": 0.0003462114405510632,
      "loss": 0.7456,
      "step": 1400
    },
    {
      "epoch": 0.4042037186742118,
      "grad_norm": 0.667991578578949,
      "learning_rate": 0.0003312368972746331,
      "loss": 0.733,
      "step": 1500
    },
    {
      "epoch": 0.4311506332524926,
      "grad_norm": 0.5126047134399414,
      "learning_rate": 0.0003162623539982031,
      "loss": 0.7188,
      "step": 1600
    },
    {
      "epoch": 0.4580975478307734,
      "grad_norm": 0.5116766691207886,
      "learning_rate": 0.000301287810721773,
      "loss": 0.7082,
      "step": 1700
    },
    {
      "epoch": 0.4850444624090542,
      "grad_norm": 0.5396955609321594,
      "learning_rate": 0.0002863132674453429,
      "loss": 0.6995,
      "step": 1800
    },
    {
      "epoch": 0.511991376987335,
      "grad_norm": 0.478701651096344,
      "learning_rate": 0.00027133872416891286,
      "loss": 0.6912,
      "step": 1900
    },
    {
      "epoch": 0.5389382915656158,
      "grad_norm": 0.4691489636898041,
      "learning_rate": 0.0002563641808924828,
      "loss": 0.6834,
      "step": 2000
    },
    {
      "epoch": 0.5658852061438965,
      "grad_norm": 0.5657579302787781,
      "learning_rate": 0.0002413896376160527,
      "loss": 0.6777,
      "step": 2100
    },
    {
      "epoch": 0.5928321207221773,
      "grad_norm": 0.4881977438926697,
      "learning_rate": 0.00022641509433962264,
      "loss": 0.6718,
      "step": 2200
    },
    {
      "epoch": 0.6197790353004581,
      "grad_norm": 0.4933091402053833,
      "learning_rate": 0.00021144055106319258,
      "loss": 0.6667,
      "step": 2300
    },
    {
      "epoch": 0.6467259498787389,
      "grad_norm": 0.47589701414108276,
      "learning_rate": 0.0001964660077867625,
      "loss": 0.661,
      "step": 2400
    },
    {
      "epoch": 0.6736728644570197,
      "grad_norm": 0.4213494062423706,
      "learning_rate": 0.00018149146451033245,
      "loss": 0.6574,
      "step": 2500
    },
    {
      "epoch": 0.7006197790353005,
      "grad_norm": 0.4284172058105469,
      "learning_rate": 0.00016651692123390236,
      "loss": 0.6521,
      "step": 2600
    },
    {
      "epoch": 0.7275666936135813,
      "grad_norm": 0.4745641350746155,
      "learning_rate": 0.0001515423779574723,
      "loss": 0.6497,
      "step": 2700
    },
    {
      "epoch": 0.7545136081918621,
      "grad_norm": 0.4352661967277527,
      "learning_rate": 0.00013656783468104223,
      "loss": 0.6469,
      "step": 2800
    },
    {
      "epoch": 0.7814605227701428,
      "grad_norm": 0.4203597605228424,
      "learning_rate": 0.00012159329140461216,
      "loss": 0.643,
      "step": 2900
    },
    {
      "epoch": 0.8084074373484236,
      "grad_norm": 0.4276147186756134,
      "learning_rate": 0.00010661874812818209,
      "loss": 0.6417,
      "step": 3000
    },
    {
      "epoch": 0.8353543519267044,
      "grad_norm": 0.39991411566734314,
      "learning_rate": 9.164420485175202e-05,
      "loss": 0.6376,
      "step": 3100
    },
    {
      "epoch": 0.8623012665049852,
      "grad_norm": 0.40398669242858887,
      "learning_rate": 7.666966157532196e-05,
      "loss": 0.6365,
      "step": 3200
    },
    {
      "epoch": 0.889248181083266,
      "grad_norm": 0.39906036853790283,
      "learning_rate": 6.169511829889188e-05,
      "loss": 0.6341,
      "step": 3300
    },
    {
      "epoch": 0.9161950956615468,
      "grad_norm": 0.39092153310775757,
      "learning_rate": 4.6720575022461816e-05,
      "loss": 0.6322,
      "step": 3400
    },
    {
      "epoch": 0.9431420102398276,
      "grad_norm": 0.3575049638748169,
      "learning_rate": 3.1746031746031745e-05,
      "loss": 0.6306,
      "step": 3500
    },
    {
      "epoch": 0.9700889248181084,
      "grad_norm": 0.37156280875205994,
      "learning_rate": 1.6771488469601677e-05,
      "loss": 0.6294,
      "step": 3600
    },
    {
      "epoch": 0.9970358393963891,
      "grad_norm": 0.3284810483455658,
      "learning_rate": 1.7969451931716085e-06,
      "loss": 0.6298,
      "step": 3700
    },
    {
      "epoch": 1.0,
      "eval_loss": 0.567869246006012,
      "eval_runtime": 4.1311,
      "eval_samples_per_second": 1210.331,
      "eval_steps_per_second": 19.123,
      "step": 3711
    }
  ],
  "logging_steps": 100,
  "max_steps": 3711,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 965640192000000.0,
  "train_batch_size": 256,
  "trial_name": null,
  "trial_params": null
}
